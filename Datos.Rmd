---
title: "Ejemplo"
output: html_document
date: "2023-09-26"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(moments) 
library(gmodels) 
library(scales)
library(survival) 
library(zoo) 
library(quantmod) 
library(vcd) 
#library(vcdExtra)
library(faraway) 
library(Hmisc) 
library(car) 
library(MASS) 
library(latticeExtra)
library(dplyr) 
#library(tidyr) 
library(ggplot2)
library(gcookbook)
library(stats)

```

La base de datos que hemos escogido se llama "Adult" y con ella vamos a predecir si los ingresos de una serie de personas superan los 50000 dólares al año según los datos del censo. Esta base de datos fue extraida por Barry Becker del censo de 1994 y tiene 48842 observaciones y 14 variables.

# Leemos los datos

La base de datos que vamos a leer contiene sólo 1550 obervaciones. Esto se debe a que hemos escogido una muestra y lo que hemos hecho es eliminar los datos directamente de la base de datos, es decir, dentro del Excel. Además, aunque la base de datos original contiene valores nulos, nosotros nos hemos fijado en ellos y al ser pocos, un (calcular porcentaje)%, y ver que no son importantes los hemos decidido eliminar.

```{r}
# Leemos los datos
datos <- read.csv('datos/AdultBueno.csv', sep = ';')
```

# División de los datos en Train, Test y Validation

Una vez leídos los datos, vamos a divirlos en tres conjuntos. 
El primero de estos, son los datos Train. Estos van a ser el 50% de los datos, y nos van a servir para entrenar los diferentes modelos.
El segundo, son los datos Test. Estos van a ser un 25% de los datos y con ellos vamos a ir evalúando el rendimiento del modelo en cada paso que demos. Nos van a servir para detectar si el modelo está sobreajustado (overfitting) o subajustado (underfitting).
Por último, los datos Validation, nos van a servir para evaluar el rendimiento final del modelo después de haber sido entrenado y ajustado usando los otros conjuntos de datos. Estos datos no van a ser utilizados ni vistos por el modelo durante el entrenamiento, para así, poder obtener obtener evaluaciones imparciales en las predicciones de nuevas obervaciones.

```{r}
# División de los datos en Train, Test y Validation
numero_filas = nrow(datos) # Miramos el número de filas
set.seed(123456) # Creamos una semilla para qu ela división siempre sea la misma
# Seleccionamos un 50% para TRAIN
indices_train = sample(1:numero_filas, .5*numero_filas)
Datos_Train = datos[indices_train,]
# Seleccionamos un 25% para TEST
indices = seq(1:numero_filas)
indices_test = sample(indices[-indices_train], .25*numero_filas)
Datos_Test = datos[indices_test,]
# Seleccionamos un 25% para VALIDATION
indices_validation = indices[-c(indices_train,indices_test)]
Datos_Validation = datos[indices_validation,]
```

# Análisis exploratorio de datos

Lo que pretendemos conseguir a partir de nuestros datos es predecir si los ingresos en un año van a ser superiores a 50000 dólares. Además, queremos ver que variables son las que más influyen en la predicción.

Para ello vamos a realizar un análisis de los datos. Vamos a empezar viendo las variables que tenemos que estudiar.

Age (edad): Variable de tipo númerico que expresa la edad de la persona.
  * El rango de valores de la edad está entre 17 y 90.

Workclass (clase de trabajo): Variable de tipo categórico que expresa la clase de trabajo que tiene la persona. Puede tomar los siguientes valores.
  * Private, persona con empleo privado
  * Self-emp-not-inc, autónomo
  * Self-emp-inc, personas que trabajan de forma independiente y han establecido       una incorporación para su negocio o actividad laboral.
  * Federal-gov, funcionario del gobierno federal
  * Local-gov, funcionario del gobierno local
  * State-gov, funcionario del gobierno estatal
  * Without-pay, persona no empleada de manera remunerada (jubilados,                  voluntariados...)
  * Never-worked, personas que nunca han trabajado
  
  
  
  
  
  

fnlwgt (peso socio-económico): Variable de tipo
Education (educación): Variable de tipo
Education num (número de educación): Variable de tipo
Marital status (estado civil): Variable de tipo
Occupation (ocupación): Variable de tipo
Relationship (relación): Variable de tipo
Race (raza): Variable de tipo
Sex (sexo): Variable de tipo
Capital gain (capital ganado): Variable de tipo
Capital loss (capital perdido): Variable de tipo
Hours per week (horas por semana): Variable de tipo
Native country (país de nacimiento): Variable de tipo
Income ():
```{r}
str(datos)
```

Hacemos un resumen rapido de los datos con la funcion summary:

```{r}

Cualitativo_Datos = data.frame(WorkClass=datos$Workclass,Education=datos$Education,EstadoCivil=datos$Marital.status,Occupation=datos$Occupation.,RelationShip=datos$Relationship,Race=datos$Race,Sex=datos$Sex,NativeCountry=datos$Native.country,Income=datos$Income.)

Cuantitativo_DatosTrain= data.frame(Age=Datos_Train$Age,FNLWGT=Datos_Train$fnlwgt,CapitalGain=Datos_Train$Capital.gain,CapitalLoss=Datos_Train$Capital.loss,Hours=Datos_Train$Hours.per.week)

Cualitativo_DatosTrain=data.frame(WorkClass=Datos_Train$Workclass,Education=Datos_Train$Education,EstadoCivil=Datos_Train$Marital.status,Occupation=Datos_Train$Occupation.,RelationShip=Datos_Train$Relationship,Race=Datos_Train$Race,Sex=Datos_Train$Sex,NativeCountry=Datos_Train$Native.country,Income=Datos_Train$Income.)

Cuantitativo_DatosTest= data.frame(Age=Datos_Test$Age,FNLWGT=Datos_Test$fnlwgt,CapitalGain=Datos_Test$Capital.gain,CapitalLoss=Datos_Test$Capital.loss,Hours=Datos_Test$Hours.per.week)

summary(Cuantitativo_DatosTrain)

# summary(datos[,c("Age","fnlwgt","Education.num","Capital.gain","Capital.loss","Hours.per.week")])
media = mean(datos$Capital.gain, na.rm =  TRUE) # le decimos que no tenga en cuenta los NA al hacer la media
```
```{r}
library(Hmisc)
describe(datos)
```
```{r}
#Grafico pairs

#Cuantitativo2= data.frame(Age=Datos_Train$Age,CapitalGain=Datos_Train$Capital.gain,CapitalLoss=Datos_Train$Capital.loss,Horas=Datos_Train$Hours.per.week)
attach(Datos_Train)
pairs(Cuantitativo_DatosTrain)
plot(Age,Hours.per.week)
cor(Cuantitativo_DatosTrain)
```


# Análisis bivariado

```{r}
#Diagramas de dispersion
qplot(Hours.per.week, fnlwgt, data = datos, colour = factor(Sex))+ geom_smooth()+
ggtitle('Relación horas trabajadas por salario.Por género')

# Comparacion del income con las edades 
ggplot(Datos_Train, aes(x = Age, fill = Income.)) + geom_bar()
# Comparacion del income con la WorkClass 
ggplot(Datos_Train, aes(x = Workclass, fill = Income.)) + geom_bar()
# Comparacion del income con la Ocupacion 
ggplot(Datos_Train, aes(x = Occupation., fill=Income.)) + geom_bar() + coord_flip()# Comparacion del income con las educacion 
ggplot(Datos_Train, aes(x = Education, fill = Income.)) + geom_bar() + coord_flip()
# Comparacion del income con el sexo 
ggplot(Datos_Train, aes(x = Sex, fill = Income.)) + geom_bar()
# Comparacion del income con las MaritalStatus 
ggplot(Datos_Train, aes(x = Marital.status, fill = Income.)) + geom_bar()
# Comparacion del income con las pais 
ggplot(Datos_Train, aes(x = Native.country, fill=Income.)) + geom_bar() + coord_flip()


# HACER BOXPLOT NO HE HECHO PORQUE NO LOS ENTIENDO
# LOS HISTOGRAMAS PARA MI NO TIENEN MUCHO SENTIDO

```

```{r}

#Histograma para la variable edad
ggplot(Cuantitativo_DatosTrain, aes(x = Age)) +
geom_histogram(fill="white", colour="black") +
ggtitle('Histograma de numero de valores de la edad asociada')

#Resto histogramas

```
Estudiamos la relacion entre las variables *sexo* y *capital.gain*



#Análisis de Componentes Principales

```{r}
#Target con colores
pca<-prcomp(Cuantitativo_DatosTrain,scale=T)

pca_dataframe <- as.data.frame(pca$x)
pca_dataframe_Income <- Datos_Train$Income.


par(mfrow=c(2,3))
ggplot(pca_dataframe, aes(x = PC1, y = PC2, color = Income.)) +
  geom_point() +
  labs(title = "PCA con Colores según el Income")

ggplot(pca_dataframe, aes(x = PC1, y = PC3, color = Income.)) +
  geom_point() +
  labs(title = "PCA con Colores según el Income")

ggplot(pca_dataframe, aes(x = PC1, y = PC4, color = Income.)) +
  geom_point() +
  labs(title = "PCA con Colores según el Income")

ggplot(pca_dataframe, aes(x = PC2, y = PC3, color = Income.)) +
  geom_point() +
  labs(title = "PCA con Colores según el Income")

ggplot(pca_dataframe, aes(x = PC2, y = PC4, color = Income.)) +
  geom_point() +
  labs(title = "PCA con Colores según el Income")

ggplot(pca_dataframe, aes(x = PC3, y = PC4, color = Income.)) +
  geom_point() +
  labs(title = "PCA con Colores según el Income")
```



```{r}
pca<-prcomp(Cuantitativo_DatosTrain,scale=T)
pca
```

PC1 asigna pesos. La mayoría de las ocasiones asigna el mismo signo a todas las covariables. En nuestro caso particular la variable FNLWGT posee signo positivo mientras que las otras poseen el signo contrario. Esto se puede interpretar de la siguiente manera:
  -	La variable FNLWGT, esta fuertemente correlacionada de forma positiva con PC1.
  -	Las variables que tienen el signo contrario sugieren una relación inversa con PC1.

Hay algunas posibles interpretaciones sobre esto, pero la que más nos convence (un vez realizado el análisis exploratorio de datos) es que  FNLWGT  tiene un impacto muy grande en la variabilidad general de los datos mientras que las demás variables, de forma INDIVIDUAL, tiene una relación no tan significativa.

Vamos a analizar y a interpretar la PC2. Esto es, las personas estarían ordenadas en cuanto a su Capital Loss en un sentido ponderando en sentido contrario el Capital Gain.

En PC3 el orden viene determinado solamente por FNLWGT.

El caso de PC4 es muy interesante pues se puede llegar a interpretar de la siguiente manera. Hay correlación negativa entre la variable Age y las horas trabajadas por semana. Luego esto quiere decir que aquellas personas que trabajan mas horas a la semana en promedio suelen ser personas jóvenes.

Si analizamos ahora PC5, observamos que  las personas estarían ordenadas en cuando a su Capital Gain en un sentido, ponderando en sentido contrario la variable edad.

## Variabilidad explicada

```{r}
plot(prcomp(Cuantitativo_DatosTrain,scale=T))
summary(prcomp(Cuantitativo_DatosTrain,scale=T))
```

Esta parte es la más importante para saber cuántas componentes elegimos. En la fila `Proportion of Variance` podemos comprobar que la proporción de varianza que explica cada una de las componentes es prácticamente la misma (en torno al 20%). Esto ya es un indicador de que este análisis no nos aclara ni nos ayuda de manera explicita a entender mejor los datos. Finalmente, se reafirma lo que estábamos intuyendo ya que en `Cumulative proportion` podemos hacernos una idea del numero de componentes principales que vamos a necesitar.

Nosotros consideramos que a partir de un 75% de variabilidad, ya es buen indicador. No obstante, este método se basa en la reducción de dimensionalidad, pero si en este caso, con el sesgo que hemos elegido, tenemos que emplear 4 componentes principales no nos resulta de gran utilidad este método.

## Análisis de los graficos

### PC1-PC2
```{r}
plot(prcomp(Cuantitativo_DatosTrain,scale=T)$x[,1:2])
```

Puntos cercanos en el mapa indican comportamiento similar en cuanto a las personas que estamos considerando en la base de datos. Del gráfico podemos inferir que hay ciertos puntos extremos en cuanto a las variables `Age`, `FNLWGT`, `Capital Gain`, `Capital Loss` y `Hours`. Pero, ¿en qué sentido? 

Esas personas situadas arriba a la izquierda de PC1 son personas con edad avanzada con un `Capital Gain` alto, `Capital Loss` alto, con muchas horas trabajadas a la semana y con un peso socio-económico (`FNLWGT`) muy bajo.

En cuanto a PC2, tenemos comportamientos extremos unos 5-10 puntos (situados abajo a la derecha) y en 5 puntos situados arriba a la izquierda.

  -	Vamos a analizar primero los 5-15 puntos. Son personas con un Capital Loss muy alto     y un Capital Gain muy bajo (esto lo sabemos gracias a los signos que nos proporciona     la tabla al realizar el summary).

  -	Los otros puntos restantes son personas con un Capital Gain muy alto y con un         Capital Loss muy bajo.

### PC1-PC3
```{r}
plot(prcomp(Cuantitativo_DatosTrain,scale=T)$x[,c(1,3)])
```

Puntos cercanos en el mapa indican comportamiento similar en cuanto a las personas que estamos considerando en la base de datos. Del gráfico podemos inferir que hay ciertos puntos extremos en cuanto a las variables `Age`, `FNLWGT`, `Capital Gain`, `Capital Loss` y `Hours`.  Pero, ¿en qué sentido? 

Esas personas situadas a la izquierda de PC1 son personas con edad avanzada con un `Capital Gain` alto, `Capital Loss` alto, con muchas horas trabajadas a la semana y con un peso socio-económico (`FNLWGT`) muy bajo.

En cuanto a PC3, tenemos comportamientos extremos en apenas 2 solos puntos, situados en la esquina superior derecha. La interpretación que podemos extraer es que son dos personas cuyo peso socioeconómico (`FNLWGT`) es mucho mas alto que el promedio de las demás personas.

### PC1-PC4
```{r}
plot(prcomp(Cuantitativo_DatosTrain,scale=T)$x[,c(1,4)])
```

Puntos cercanos en el mapa indican comportamiento similar en cuanto a las personas que estamos considerando en la base de datos. Del gráfico podemos inferir que hay ciertos puntos extremos en cuanto a las variables Age`, `FNLWGT`, `Capital Gain`, `Capital Loss` y `Hours`. Pero, ¿en qué sentido?

Esas personas situadas a la izquierda de PC1 son personas con edad avanzada con un `Capital Gain` alto, `Capital Loss` alto, con muchas horas trabajadas a la semana y con un peso socio-económico (`FNLWGT`) muy bajo.

Analicemos en este punto PC4. En este sentido tenemos comportamientos extremos en 1 solo punto. Esa persona posee una edad muy avanzada y trabaja pocas horas a la semana.

### Graficos restantes
```{r}
par(mfrow=c(2,3))
### PC2-PC3
plot(prcomp(Cuantitativo_DatosTrain,scale=T)$x[,c(2,3)])
### PC2-PC4
plot(prcomp(Cuantitativo_DatosTrain,scale=T)$x[,c(2,4)])
### PC3-PC4
plot(prcomp(Cuantitativo_DatosTrain,scale=T)$x[,c(3,4)])
```

En cuanto a las otras 3 graficas restantes, el procedimiento es el mismo. Es decir, buscar posibles puntos (personas) extremos y analizar que propiedades tienen.

Una pequeña barrera que tiene el PCA, es que solo tiene en cuenta las variables CUANTITATIVAS de la base de datos. Esto significa que no podemos asegurar ni extrapolar nada sobre las otras variables CUALITATIVAS que tenemos en nuestra base de datos en nuestro análisis de componentes principales.


Para finalizar esta parte del trabajo vamos a realizar un gráfico `biplot` para ayudar a visualizar las relaciones entre variables y observaciones.

## Grafico "biplot".
```{r}
biplot(pca)
```

Los estados casi se ordenan en la componente PC2 por Capital Gain en un sentido, y por Capital Loss en el otro, como ya hemos comprobado anteriormente.

# Analisis Cluster
```{r}
n = dim(datos)[1]
p = dim(datos)[2]
DatosTrainEscalados <- scale(Cuantitativo_DatosTrain)
clusters2.datos=kmeans(DatosTrainEscalados,centers=2,nstart=25)
clusters2.datos$cluster
clusters2.datos$withinss

clusters3.datos=kmeans(DatosTrainEscalados,centers=3,nstart=25)
clusters3.datos$cluster
clusters3.datos$withinss

clusters4.datos=kmeans(DatosTrainEscalados,centers=4,nstart=25)
clusters4.datos$cluster
clusters4.datos$withinss

clusters7.datos=kmeans(DatosTrainEscalados,centers=7,nstart=25)
clusters7.datos$cluster
clusters7.datos$withinss


#Inicializamos el vector
SSW <- vector(mode = "numeric", length = 15)

#Variabilidad de todos los datos, es decir, todos los datos como un único cluster
SSW[1] <- (n - 1) * sum(apply(DatosTrainEscalados,2,var)) 

#Variabilidad de cada modelo, desde 2 clusters hasta 15 clusters
for (i in 2:15) SSW[i] <- sum(kmeans(DatosTrainEscalados,centers=i,nstart=25)$withinss)

#Dibujamos un gráfico con el resultado
plot(1:15, SSW, type="b", xlab="Number of Clusters", ylab="Sum of squares within groups",pch=19, col="steelblue4")

centroides=aggregate(DatosTrainEscalados,by=list(clusters4.datos $cluster),FUN=mean)
t(centroides)  
# Dibujamos los clusters en el scatterplot (variables 2a2)
nk=4 # nk es el numero de clusters 
pairs(DatosTrainEscalados,col= clusters4.datos$cluster,pch=19)
points(clusters4.datos$centers, col = 1:nk, pch = 19, cex=2)

#Para 7
centroides=aggregate(DatosTrainEscalados,by=list(clusters7.datos $cluster),FUN=mean)
t(centroides)  
# Dibujamos los clusters en el scatterplot (variables 2a2)
nk=7 # nk es el numero de clusters 
pairs(DatosTrainEscalados,col= clusters7.datos$cluster,pch=19)
points(clusters7.datos$centers, col = 1:nk, pch = 19, cex=2)


# ISAAC
library(NbClust)
nb <- NbClust(DatosTrainEscalados, distance = "euclidean", min.nc = 2, max.nc = 15, method = "kmeans")

library(parameters)

# Ponemos los dos para comparar, el 7  lo dice el metodo el 4 pues para ver que pasa con menos
res_kmeans <- cluster_analysis(DatosTrainEscalados, n=4, method="kmeans")
plot(summary(res_kmeans))
 
res_kmeans <- cluster_analysis(DatosTrainEscalados, n=7, method="kmeans")
plot(summary(res_kmeans))


```
```{r}
# El grafico que sirve no nos vale ya que tenemos muchos datos y no se ve claramente
# # Guardamos el vector con el cluster correspondiente a cada país
# datos.clusters7 <- clusters7.datos$cluster
# # Vamos a hacer PCA para poder graficar los clusters en 2dimensiones!
# library(cluster)
# clusplot(DatosTrainEscalados, datos.clusters7, color=TRUE, shade=TRUE, labels=2,lines=0)

```

# Métodos jerarquicos

```{r}
#Probamos varios metodos de agrupacion y nos damos cuenta que el mejor es
# Primero obtenemos la matriz de distancias
d <- dist(Cuantitativo_DatosTrain, method = "euclidean")
fit <- hclust(d, method="ward.D")
plot(fit, labels=rownames(Cuantitativo_DatosTrain),cex=0.7)#Este

fit2 <- hclust(d, method="single")
plot(fit2, labels=rownames(Cuantitativo_DatosTrain),cex=0.7)#Este no

fit3 <- hclust(d, method="complete")
plot(fit3, labels=rownames(Cuantitativo_DatosTrain),cex=0.7)#Este no

fit4 <- hclust(d, method="average")
plot(fit4, labels=rownames(Cuantitativo_DatosTrain),cex=0.7)#Este no

fit5 <- hclust(d, method="mcquitty")
plot(fit5, labels=rownames(Cuantitativo_DatosTrain),cex=0.7)#Este no

fit6 <- hclust(d, method="median")
plot(fit6, labels=rownames(Cuantitativo_DatosTrain),cex=0.7)#Este no

fit7 <- hclust(d, method="centroid")
plot(fit7, labels=rownames(Cuantitativo_DatosTrain),cex=0.7)#Este no


```

```{r}


##
## FALTA HACER UN CLUSTER DE LOS PCA
##

#library(factoextra)
#fviz_cluster(clusters7.datos, data = Cuantitativo_DatosTrain)

groups <- cutree(fit, k=7) # Fijamos en 7 el número de clusters
plot(pca,col=groups)


rect.hclust(fit, k=7, border="red")




centroides=aggregate(DatosTrainEscalados,by=list(clusters7.datos $cluster),FUN=mean)
t(centroides)  
# Dibujamos los clusters en el scatterplot (variables 2a2)
nk=7 # nk es el numero de clusters 
pairs(DatosTrainEscalados,col= clusters7.datos$cluster,pch=19)
points(clusters7.datos$centers, col = 1:nk, pch = 19, cex=2)

```

```{r}
library(class)
c2 <- factor(Datos_Train$Income.,labels = c(">50K", "<=50K"))
k1 = length(datos$Age)^((4)/(14+4))
modelo1 <- knn(train = Cuantitativo_DatosTrain, test = Cuantitativo_DatosTest, cl = c2, k = k1)

table(modelo1, Datos_Test$Income.)
# Falta graficar esto 
```

#Arboles de decision

```{r}
#Convertimos las variables cualitativas en factores

Datos_con_Factores <- datos
Datos_con_Factores[,2] = as.factor(Datos_con_Factores[,2])
Datos_con_Factores[,4] = as.factor(Datos_con_Factores[,4])
Datos_con_Factores[,6] = as.factor(Datos_con_Factores[,6])
Datos_con_Factores[,7] = as.factor(Datos_con_Factores[,7])
Datos_con_Factores[,8] = as.factor(Datos_con_Factores[,8])
Datos_con_Factores[,9] = as.factor(Datos_con_Factores[,9])
Datos_con_Factores[,10] = as.factor(Datos_con_Factores[,10])
Datos_con_Factores[,14] = as.factor(Datos_con_Factores[,14])
Datos_con_Factores[,15] = as.factor(Datos_con_Factores[,15])


library(rpart)
set.seed(123)
Datos_con_Factores.rp <- rpart(Datos_con_Factores[,15] ~., data=Datos_con_Factores[,1:14], method="class", cp=0.0001, parms=list(split="information"))

#graficamos y vemos el parámetro de complejidad
plotcp(Datos_con_Factores.rp) #<-- El parametro de complejidad es 0,037. Nos quedamos con 0,03
printcp(Datos_con_Factores.rp)


# La grafica significa que combina la tasa de acierto con la profundidad del arbol. La forma de esta grfica significa que hay un momento en el cual la profundidad del arbol es mayor pero no mejora la tasa de acierto.

Datos_Train_con_Factores = Datos_Train
Datos_Train_con_Factores[,2] = as.factor(Datos_Train_con_Factores[,2])
Datos_Train_con_Factores[,4] = as.factor(Datos_Train_con_Factores[,4])
Datos_Train_con_Factores[,6] = as.factor(Datos_Train_con_Factores[,6])
Datos_Train_con_Factores[,7] = as.factor(Datos_Train_con_Factores[,7])
Datos_Train_con_Factores[,8] = as.factor(Datos_Train_con_Factores[,8])
Datos_Train_con_Factores[,9] = as.factor(Datos_Train_con_Factores[,9])
Datos_Train_con_Factores[,10] = as.factor(Datos_Train_con_Factores[,10])
Datos_Train_con_Factores[,14] = as.factor(Datos_Train_con_Factores[,14])
Datos_Train_con_Factores[,15] = as.factor(Datos_Train_con_Factores[,15])

Datos_Test_con_Factores = Datos_Test
Datos_Test_con_Factores[,2] = as.factor(Datos_Test_con_Factores[,2])
Datos_Test_con_Factores[,4] = as.factor(Datos_Test_con_Factores[,4])
Datos_Test_con_Factores[,6] = as.factor(Datos_Test_con_Factores[,6])
Datos_Test_con_Factores[,7] = as.factor(Datos_Test_con_Factores[,7])
Datos_Test_con_Factores[,8] = as.factor(Datos_Test_con_Factores[,8])
Datos_Test_con_Factores[,9] = as.factor(Datos_Test_con_Factores[,9])
Datos_Test_con_Factores[,10] = as.factor(Datos_Test_con_Factores[,10])
Datos_Test_con_Factores[,14] = as.factor(Datos_Test_con_Factores[,14])
Datos_Test_con_Factores[,15] = as.factor(Datos_Test_con_Factores[,15])



#Añadimos al train la fila que tiene Preschool pq esta en los test y no en el train
Datos_Train_con_Factores <- rbind(Datos_Train_con_Factores, Datos_Test_con_Factores[c('209'),])

# Predict con todos los datos de la tabla
n=dim(Datos_con_Factores)[1]
y.pred=predict(Datos_con_Factores.rp,Datos_con_Factores[,-c(15)])
factores=colnames(y.pred)
y.pred.fact=matrix(0,n,1)
for (i in 1:n)
y.pred.fact[i]= factores[which.max(y.pred[i,])]
y.real.fact=Datos_con_Factores[,15]
table(y.pred.fact,y.real.fact) #<-Tabla de predicciones frente a valor real de todos los datos.
# sum(y.real.fact=="buff")
# sum(y.real.fact=="sick")



x.train=Datos_Train_con_Factores
x.test=Datos_Test_con_Factores

#Datos train
Datos_Train_con_Factores.rp <- rpart(x.train[,15] ~., data=x.train[,1:14], cp=0.04, parms=list(split="information"))
k=dim(x.train)[1]
y.pred.train=predict(Datos_Train_con_Factores.rp, x.train[,-c(15)])
factores=colnames(y.pred.train)
y.pred.train.fact=matrix(0,k,1)
for (i in 1:k)
y.pred.train.fact[i]= factores[which.max(y.pred.train[i,])]
y.real.train.fact=x.train[,15]
table.rpart.train=table(y.pred.train.fact,y.real.train.fact)


#datos test
##Datos_Test_con_Factores = Datos_Test_con_Factores[Datos_Test_con_Factores$Education != 'Preschool',]
m=dim(x.test)[1] #tamanno de la muestra de test
y.pred.test=predict(Datos_Train_con_Factores.rp, x.test[,-c(15)])
factores=colnames(y.pred.test)
y.pred.test.fact =factores[max.col(y.pred.test)]
y.real.test.fact=x.test[,15]
table.rpart.test=table(y.pred.test.fact,y.real.test.fact)


```

```{r}
#Random Forest
#RANDOM Forest Cleveland
library(randomForest)
set.seed(123)
#Como da error en el test y no tiene sentido, es algo de que no estan relacionadas las tablas del train y del test
# pues metemos una fila del train en el test y la quitamos y asi se relacionan
x.test <- rbind(x.train[1,],x.test)
x.test <- x.test[-1,]

Datos_con_Factores.rf <- randomForest(x.train[,1:14], as.factor(x.train[,15]), ntree=100, importance=FALSE, proximity=TRUE, mtry=4, replace=FALSE)
y.pred.test.rf=predict(Datos_con_Factores.rf, x.test[,-c(15)])
table.libreria.test=table(y.pred.test.rf,  as.factor(x.test[,15]))
y.pred.train.rf= predict(Datos_con_Factores.rf, x.train[,-c(15)])
table.libreria.train=table(y.pred.train.rf,  as.factor(x.train[,15]))
print(table.libreria.test)
print(table.libreria.train)




# Hay que ponerlo como factor y no se como se hace pq las predicciones las hemos hecho con factores, no se si se puede hacer el modelo sin factores. Luego hay que añadir un dato de x.train y quitarlo pq si no da error
datoNuevo <- data.frame(Age = 38, Workclass = "Private", fnlwgt = 125467, Education = "Bachelors", Education.num = 13, Marital.status = "Divorced", Occupation. = "Sales", Relationship = "Husband", Race = "White", Sex = "Female", Capital.gain = 1500, Capital.loss = 2000, Hours.per.week = 40, Native.country = "United-States", Income. = ">50K")


#datoNuevo <- datos[1,]

datoNuevo <- rbind(x.train[1,],datoNuevo)
datoNuevo <- datoNuevo[-1,]


prediccionDatoNuevo=predict(Datos_con_Factores.rf, datoNuevo)


```











