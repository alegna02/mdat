---
title: "Ejemplo"
output: html_document
date: "2023-09-26"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(moments) 
library(gmodels) 
library(scales)
library(survival) 
library(zoo) 
library(quantmod) 
library(vcd) 
library(vcdExtra)
library(faraway) 
library(Hmisc) 
library(car) 
library(MASS) 
library(latticeExtra)
library(dplyr) 
library(tidyr) 
library(ggplot2)
library(gcookbook)
library(stats)

```

 
# Division de datos en Training Test

```{r}

#setwd('C:/Users/angyp/Desktop/prueba')
datos <- read.csv('datos/AdultBueno.csv', sep = ';')

# TRAIN TEST VALIDATION
numero_total = nrow(datos)
set.seed(123456) # reproductivilidad
# 50% para TRAIN
indices_train = sample(1:numero_total, .5*numero_total)
Datos_Train = datos[indices_train,]
# 25% para TEST
indices = seq(1:numero_total)
indices_test = sample(indices[-indices_train], .25*numero_total)
Datos_Test = datos[indices_test,]
# 25% para VALIDATION
indices_validation = indices[-c(indices_train,indices_test)]
```

# Analisis exploratorio de datos
```{r}
str(datos)
```

Hacemos un resumen rapido de los datos con la funcion summary:

```{r}

Cuantitativo= data.frame(Age=Datos_Train$Age,FNLWGT=Datos_Train$fnlwgt,CapitalGain=Datos_Train$Capital.gain,CapitalLoss=Datos_Train$Capital.loss,Hours=Datos_Train$Hours.per.week)

Cualitativo=data.frame(WorkClass=Datos_Train$Workclass,Education=Datos_Train$Education,EstadoCivil=Datos_Train$Marital.status,Occupation=Datos_Train$Occupation.,RelationShip=Datos_Train$Relationship,Race=Datos_Train$Race,Sex=Datos_Train$Sex,NativeCountry=Datos_Train$Native.country,Income=Datos_Train$Income.)

CuantitativoTest= data.frame(Age=Datos_Test$Age,FNLWGT=Datos_Test$fnlwgt,CapitalGain=Datos_Test$Capital.gain,CapitalLoss=Datos_Test$Capital.loss,Hours=Datos_Test$Hours.per.week)

summary(Cuantitativo)

# summary(datos[,c("Age","fnlwgt","Education.num","Capital.gain","Capital.loss","Hours.per.week")])
media = mean(datos$Capital.gain, na.rm =  TRUE) # le decimos que no tenga en cuenta los NA al hacer la media
```
```{r}
library(Hmisc)
describe(datos)
```
```{r}
#Grafico pairs

#Cuantitativo2= data.frame(Age=Datos_Train$Age,CapitalGain=Datos_Train$Capital.gain,CapitalLoss=Datos_Train$Capital.loss,Horas=Datos_Train$Hours.per.week)
attach(Datos_Train)
pairs(Cuantitativo)
plot(Age,Hours.per.week)
cor(Cuantitativo)
```


# Análisis bivariado

```{r}
#Diagramas de dispersion
qplot(Hours.per.week, fnlwgt, data = datos, colour = factor(Sex))+ geom_smooth()+
ggtitle('Relación horas trabajadas por salario.Por género')

# Comparacion del income con las edades 
ggplot(Datos_Train, aes(x = Age, fill = Income.)) + geom_bar()
# Comparacion del income con la WorkClass 
ggplot(Datos_Train, aes(x = Workclass, fill = Income.)) + geom_bar()
# Comparacion del income con la Ocupacion 
ggplot(Datos_Train, aes(x = Occupation., fill=Income.)) + geom_bar() + coord_flip()# Comparacion del income con las educacion 
ggplot(Datos_Train, aes(x = Education, fill = Income.)) + geom_bar() + coord_flip()
# Comparacion del income con el sexo 
ggplot(Datos_Train, aes(x = Sex, fill = Income.)) + geom_bar()
# Comparacion del income con las MaritalStatus 
ggplot(Datos_Train, aes(x = Marital.status, fill = Income.)) + geom_bar()
# Comparacion del income con las pais 
ggplot(Datos_Train, aes(x = Native.country, fill=Income.)) + geom_bar() + coord_flip()


# HACER BOXPLOT NO HE HECHO PORQUE NO LOS ENTIENDO
# LOS HISTOGRAMAS PARA MI NO TIENEN MUCHO SENTIDO

```

```{r}

#Histograma para la variable edad
ggplot(Cuantitativo, aes(x = Age)) +
geom_histogram(fill="white", colour="black") +
ggtitle('Histograma de numero de valores de la edad asociada')

#Resto histogramas

```
Estudiamos la relacion entre las variables *sexo* y *capital.gain*


```{r}

```
#Componentes Principales

```{r}
#Vemos los primeros datos
head(Datos_Train)

pca<-prcomp(Cuantitativo,scale=T)
pca
plot(prcomp(Cuantitativo,scale=T))
summary(prcomp(Cuantitativo,scale=T))
par(mfrow=c(2,3))
plot(prcomp(Cuantitativo,scale=T)$x[,1:2])
plot(prcomp(Cuantitativo,scale=T)$x[,c(1,3)])
plot(prcomp(Cuantitativo,scale=T)$x[,c(1,4)])
plot(prcomp(Cuantitativo,scale=T)$x[,c(2,3)])
plot(prcomp(Cuantitativo,scale=T)$x[,c(2,4)])
plot(prcomp(Cuantitativo,scale=T)$x[,c(3,4)])

## FALTA poner target con colores
```

# Analisis Cluster
```{r}
n = dim(datos)[1]
p = dim(datos)[2]
DatosTrainEsc <- scale(Cuantitativo)
clusters2.datos=kmeans(DatosTrainEsc,centers=2,nstart=25)
clusters2.datos$cluster
clusters2.datos$withinss

clusters3.datos=kmeans(DatosTrainEsc,centers=3,nstart=25)
clusters3.datos$cluster
clusters3.datos$withinss

clusters4.datos=kmeans(DatosTrainEsc,centers=4,nstart=25)
clusters4.datos$cluster
clusters4.datos$withinss

clusters7.datos=kmeans(DatosTrainEsc,centers=7,nstart=25)
clusters7.datos$cluster
clusters7.datos$withinss


#Inicializamos el vector
SSW <- vector(mode = "numeric", length = 15)

#Variabilidad de todos los datos, es decir, todos los datos como un único cluster
SSW[1] <- (n - 1) * sum(apply(DatosTrainEsc,2,var)) 

#Variabilidad de cada modelo, desde 2 clusters hasta 15 clusters
for (i in 2:15) SSW[i] <- sum(kmeans(DatosTrainEsc,centers=i,nstart=25)$withinss)

#Dibujamos un gráfico con el resultado
plot(1:15, SSW, type="b", xlab="Number of Clusters", ylab="Sum of squares within groups",pch=19, col="steelblue4")

centroides=aggregate(DatosTrainEsc,by=list(clusters4.datos $cluster),FUN=mean)
t(centroides)  
# Dibujamos los clusters en el scatterplot (variables 2a2)
nk=4 # nk es el numero de clusters 
pairs(DatosTrainEsc,col= clusters4.datos$cluster,pch=19)
points(clusters4.datos$centers, col = 1:nk, pch = 19, cex=2)

#Para 7
centroides=aggregate(DatosTrainEsc,by=list(clusters7.datos $cluster),FUN=mean)
t(centroides)  
# Dibujamos los clusters en el scatterplot (variables 2a2)
nk=7 # nk es el numero de clusters 
pairs(DatosTrainEsc,col= clusters7.datos$cluster,pch=19)
points(clusters7.datos$centers, col = 1:nk, pch = 19, cex=2)


# ISAAC
library(NbClust)
nb <- NbClust(DatosTrainEsc, distance = "euclidean", min.nc = 2, max.nc = 15, method = "kmeans")

library(parameters)

# Ponemos los dos para comparar, el 7  lo dice el metodo el 4 pues para ver que pasa con menos
res_kmeans <- cluster_analysis(DatosTrainEsc, n=4, method="kmeans")
plot(summary(res_kmeans))
 
res_kmeans <- cluster_analysis(DatosTrainEsc, n=7, method="kmeans")
plot(summary(res_kmeans))


```
```{r}
# El grafico que sirve no nos vale ya que tenemos muchos datos y no se ve claramente
# # Guardamos el vector con el cluster correspondiente a cada país
# datos.clusters7 <- clusters7.datos$cluster
# # Vamos a hacer PCA para poder graficar los clusters en 2dimensiones!
# library(cluster)
# clusplot(DatosTrainEsc, datos.clusters7, color=TRUE, shade=TRUE, labels=2,lines=0)

```

# Métodos jerarquicos

```{r}
#Probamos varios metodos de agrupacion y nos damos cuenta que el mejor es
# Primero obtenemos la matriz de distancias
d <- dist(Cuantitativo, method = "euclidean")
fit <- hclust(d, method="ward.D")
plot(fit, labels=rownames(Cuantitativo),cex=0.7)#Este

fit2 <- hclust(d, method="single")
plot(fit2, labels=rownames(Cuantitativo),cex=0.7)#Este no

fit3 <- hclust(d, method="complete")
plot(fit3, labels=rownames(Cuantitativo),cex=0.7)#Este no

fit4 <- hclust(d, method="average")
plot(fit4, labels=rownames(Cuantitativo),cex=0.7)#Este no

fit5 <- hclust(d, method="mcquitty")
plot(fit5, labels=rownames(Cuantitativo),cex=0.7)#Este no

fit6 <- hclust(d, method="median")
plot(fit6, labels=rownames(Cuantitativo),cex=0.7)#Este no

fit7 <- hclust(d, method="centroid")
plot(fit7, labels=rownames(Cuantitativo),cex=0.7)#Este no


```

```{r}


##
## FALTA HACER UN CLUSTER DE LOS PCA
##

groups <- cutree(fit, k=7) # Fijamos en 7 el número de clusters
plot(pca,col=groups)


rect.hclust(fit, k=7, border="red")




centroides=aggregate(DatosTrainEsc,by=list(clusters7.datos $cluster),FUN=mean)
t(centroides)  
# Dibujamos los clusters en el scatterplot (variables 2a2)
nk=7 # nk es el numero de clusters 
pairs(DatosTrainEsc,col= clusters7.datos$cluster,pch=19)
points(clusters7.datos$centers, col = 1:nk, pch = 19, cex=2)

```

```{r}
library(class)
c1 <- factor(Datos_Train$Income.,labels = c(">50K", "<=50K"))
k = length(datos$Age)^((4)/(14+4))
modelo1 <- knn(train = Cuantitativo, test = CuantitativoTest, cl = c1, k = k)

table(modelo1, Datos_Test$Income.)
# Falta graficar esto 
```

#Arboles de decision

```{r}
#Convertimos las variables cualitativas en factores
datos2<-read.csv('datos/AdultBueno.csv', sep = ';')
datos2[,2] = as.factor(datos[,2])
datos2[,4] = as.factor(datos[,4])
datos2[,6] = as.factor(datos[,6])
datos2[,7] = as.factor(datos[,7])
datos2[,8] = as.factor(datos[,8])
datos2[,9] = as.factor(datos[,9])
datos2[,10] = as.factor(datos[,10])
datos2[,14] = as.factor(datos[,14])
datos2[,15] = as.factor(datos[,15])

library(rpart)
set.seed(123)
datos2.rp <- rpart(datos2[,15] ~., data=datos2[,1:14], method="class", cp=0.0001, parms=list(split="information"))

#graficamos y vemos el parámetro de complejidad
plotcp(datos2.rp) #<-- El parametro de complejidad es 0,037. Nos quedamos con 0,03
printcp(datos2.rp)


# La grafica significa que combina la tasa de acierto con la profundidad del arbol. La forma de esta grfica significa que hay un momento en el cual la profundidad del arbol es mayor pero no mejora la tasa de acierto.

Datos_Train2 = Datos_Train
Datos_Train2[,2] = as.factor(Datos_Train[,2])
Datos_Train2[,4] = as.factor(Datos_Train[,4])
Datos_Train2[,6] = as.factor(Datos_Train[,6])
Datos_Train2[,7] = as.factor(Datos_Train[,7])
Datos_Train2[,8] = as.factor(Datos_Train[,8])
Datos_Train2[,9] = as.factor(Datos_Train[,9])
Datos_Train2[,10] = as.factor(Datos_Train[,10])
Datos_Train2[,14] = as.factor(Datos_Train[,14])
Datos_Train2[,15] = as.factor(Datos_Train[,15])

Datos_Test2 = Datos_Test
Datos_Test2[,2] = as.factor(Datos_Test[,2])
Datos_Test2[,4] = as.factor(Datos_Test[,4])
Datos_Test2[,6] = as.factor(Datos_Test[,6])
Datos_Test2[,7] = as.factor(Datos_Test[,7])
Datos_Test2[,8] = as.factor(Datos_Test[,8])
Datos_Test2[,9] = as.factor(Datos_Test[,9])
Datos_Test2[,10] = as.factor(Datos_Test[,10])
Datos_Test2[,14] = as.factor(Datos_Test[,14])
Datos_Test2[,15] = as.factor(Datos_Test[,15])



n=dim(datos2)[1]
y.pred=predict(datos2.rp,datos2[,-c(15)])
factores=colnames(y.pred)
y.pred.fact=matrix(0,n,1)
for (i in 1:n)
y.pred.fact[i]= factores[which.max(y.pred[i,])]
y.real.fact=datos2[,15]
table(y.pred.fact,y.real.fact) #<-Tabla de predicciones frente a valor real de todos los datos.
# sum(y.real.fact=="buff")
# sum(y.real.fact=="sick")



x.train=Datos_Train2
x.test=Datos_Test2

#Datos train
Datos_Train2.rp <- rpart(x.train[,15] ~., data=x.train[,1:14], cp=0.04, parms=list(split="information"))
k=dim(x.train)[1]
y.pred.train=predict(Datos_Train2.rp, x.train[,-c(15)])
factores=colnames(y.pred.train)
y.pred.train.fact=matrix(0,k,1)
for (i in 1:k)
y.pred.train.fact[i]= factores[which.max(y.pred.train[i,])]
y.real.train.fact=x.train[,15]
table.rpart.train=table(y.pred.train.fact,y.real.train.fact)


#datos test
##Datos_Test2 = Datos_Test2[Datos_Test2$Education != 'Preschool',]
m=dim(x.test)[1] #tamanno de la muestra de test
y.pred.test=predict(Datos_Train2.rp, x.test[,-c(15)])
factores=colnames(y.pred.test)
y.pred.test.fact =factores[max.col(y.pred.test)]
y.real.test.fact=x.test[,15]
table.rpart.test=table(y.pred.test.fact,y.real.test.fact)


```












