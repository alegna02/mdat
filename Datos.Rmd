---
title: "Ejemplo"
output: html_document
date: "2023-09-26"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(moments) 
library(gmodels) 
library(scales)
library(survival) 
library(zoo) 
library(quantmod) 
library(vcd) 
#library(vcdExtra)
library(faraway) 
library(Hmisc) 
library(car) 
library(MASS) 
library(latticeExtra)
library(dplyr) 
#library(tidyr) 
library(ggplot2)
library(gcookbook)
library(stats)
library(e1071)
```

# Preguntas de interés (Bussiness understanding)

1. ¿Hay algun tipo de sesgo en cuanto al sexo de las personas?

2. ¿Es cierto que todas las variables aportan informacion significativa?

3. ¿Habra algun modelo que prediga mejor de

4. ¿Es proporcional el nivel de educacion junto con la profesion que se ocupa a la cantidad de ingreso que genera?

5. Teniendo en cuenta que el PCA solo tiene en cuenta variables que son cuantitavivas, ¿es buena idea considerar este modelo como un candidato a mejor modelo predictivo?

6.

7. ¿

8.

9. ¿Cual es el mejor kernel para la separacion de nuestros datos?

La base de datos que hemos escogido se llama "Adult" y con ella vamos a predecir si los ingresos de una serie de personas superan los 50000 dólares al año según los datos del censo. Esta base de datos fue extraida por Barry Becker del censo de 1994 y tiene 48842 observaciones y 14 variables.

# Leemos los datos

La base de datos que vamos a leer contiene sólo 1550 obervaciones. Esto se debe a que hemos escogido una muestra de la base de datos y lo que hemos hecho es eliminar los datos directamente de la base de datos, es decir, dentro del Excel. Además, aunque la base de datos original contiene valores nulos, nosotros nos hemos fijado en ellos y al ser pocos, un (calcular porcentaje)%, y ver que no son importantes los hemos decidido eliminar.

```{r}
# Leemos los datos
datos <- read.csv('datos/AdultBueno.csv', sep = ';')
```

# División de los datos en Train, Test y Validation

Una vez leídos los datos, vamos a divirlos en tres conjuntos. 
El primero de estos, son los datos Train. Estos van a ser el 50% de los datos, y nos van a servir para entrenar los diferentes modelos.
El segundo, son los datos Test. Estos van a ser un 25% de los datos y con ellos vamos a ir evalúando el rendimiento del modelo en cada paso que demos. Nos van a servir para detectar si el modelo está sobreajustado (overfitting) o subajustado (underfitting).
Por último, los datos Validation, nos van a servir para evaluar el rendimiento final del modelo después de haber sido entrenado y ajustado usando los otros conjuntos de datos. Estos datos no van a ser utilizados ni vistos por el modelo durante el entrenamiento, para así, poder obtener obtener evaluaciones imparciales en las predicciones de nuevas obervaciones.

```{r}
# División de los datos en Train, Test y Validation
numero_filas = nrow(datos) # Miramos el número de filas
set.seed(123456) # Creamos una semilla para qu ela división siempre sea la misma
# Seleccionamos un 50% para TRAIN
indices_train = sample(1:numero_filas, .5*numero_filas)
Datos_Train = datos[indices_train,]
# Seleccionamos un 25% para TEST
indices = seq(1:numero_filas)
indices_test = sample(indices[-indices_train], .25*numero_filas)
Datos_Test = datos[indices_test,]
# Seleccionamos un 25% para VALIDATION
indices_validation = indices[-c(indices_train,indices_test)]
Datos_Validation = datos[indices_validation,]
```

# Análisis exploratorio de datos

Lo que pretendemos conseguir a partir de nuestros datos es predecir si los ingresos en un año van a ser superiores a 50000 dólares. Además, queremos ver que variables son las que más influyen en la predicción.

Para ello vamos a realizar un análisis de los datos. Vamos a empezar viendo las variables que tenemos que estudiar.


Age (edad): Variable de tipo númerico que expresa la edad de la persona.
  * El rango de valores de la edad está entre 17 y 90.


Workclass (clase de trabajo): Variable de tipo categórico que expresa la clase de trabajo que tiene la persona. Puede tomar los siguientes valores.
  * Private, persona con empleo privado.
  * Self-emp-not-inc, autónomo.
  * Self-emp-inc, personas que trabajan por cuenta propia en una incorporación o negocio propio. 
  * Federal-gov, funcionario del gobierno federal.
  * Local-gov, funcionario del gobierno local.
  * State-gov, funcionario del gobierno estatal.
  * Without-pay, persona no empleada de manera remunerada (jubilados, voluntariados...).
  * Never-worked, personas que nunca han trabajado.
  
  
fnlwgt (peso socio-económico): Variable de tipo númerico que representa el peso socio económico. 


Education (educación): Variable de tipo categórico que representa el nivel educativo alcanzado por una persona. Puede tomar los siguientes valores.
  * Bachelors, grado universitario.
  * Some-college, universitarios sin licenciatura.
  * 11th, 11º de secundaria.
  * HS-grad, graduado en secundaria.
  * Prof-school, educación profesional, tras obtener una licenciatura.
  * Assoc-acdm, título de asociado en un campo académico.
  * Assoc-voc, título de asociado en un campo vocacional.
  * 9th, 9º de secundaria.
  * 7th-8th, 7º y 8º de secundaria.
  * 12th, 12º de secundaria.
  * Masters, máster universitario.
  * 1st-4th, 1º a 4º de secundaria.
  * 10th, 10º de secundaria.
  * Doctorate, doctorado.
  * 5th-6th, 5º y 6º de secundaria.
  * Preschool, preescolar.


Education num (número de educación): Variable de tipo númerico que representa los valores anteriores. Cada categoría tiene asociado un número, donde un mayor valor significa mayor nivel de estudio.


Marital status (estado civil): Variable de tipo categórica que describe el estado civil de un individuo. Puede tomar los siguientes valores.
  * Married-civ-spouse, casado con cónyuge civil.
  * Divorced, divorciado.
  * Never-married, nunca casado.
  * Separated, separado.
  * Widowed, viudo.
  * Married-spouse-absent, casado, con cónyuge ausente.
  * Married-AF-spouse, casado, con cónyuge en las Fuerzas Armadas.


Occupation (ocupación): Variable de tipo categórica que describe el tipo de trabajo de la persona. Puede tomar los siguientes valores.
  * Tech-support, soporte técnico.
  * Craft-repair, reparación.
  * Other-service, otros servicios.
  * Sales, ventas.
  * Exec-managerial, ejecutivo o gerencial.
  * Prof-specialty, especialidad profesional.
  * Handlers-cleaners, manipuladores y limpiadores.
  * Machine-op-inspct, operadores de máquinas e inspectores.
  * Adm-clerical, administrativo.
  * Farming-fishing, agricultura y pesca.
  * Transport-moving, transporte y mudanzas.
  * Priv-house-serv, servicio doméstico privado.
  * Protective-serv, servicios de protección (policía o bombero).
  * Armed-Forces, fuerzas armadas.


Relationship (relación): Variable de tipo categórica que describe el tipo de posición familiar de la persona. Puede tomar los siguientes valores.
  * Wife, esposo.
  * Own-child, hijo único.
  * Husband, marido/mujer.
  * Not-in-family, no pertenece a la familia.
  * Other-relative, otro pariente.
  * Unmarried, no casado.


Race (raza): Variable de tipo categórica que describe la raza de la persona. Puede tomar los siguientes valores.
  * White, blanco.
  * Asian-Pac-Islander, asiático-isleño del Pacífico.
  * Amer-Indian-Eskimo, nativos americanos o indígenas americanos.
  * Other, otro.
  * Black, negro.


Sex (sexo): Variable de tipo binaria que representa el sexo de la persona, puede tomar el valor de mujer (Female) y hombre (Male).


Capital gain (capital ganado): Variable de tipo numérica que se refiere a la ganancia de capital, es la diferencia positiva entre el precio de venta y el precio de compra en una inversión.


Capital loss (capital perdido): Variable de tipo numérica que se refiere a la pérdida de capital, es la diferencia negativa entre el precio de compra y el precio de venta en una inversión.


Hours per week (horas por semana): Variable de tipo númerico que indica las horas trabajadas por semana por la persona.


Native country (país de nacimiento): Variable de tipo categórica que indica el país en el que ha nacido la persona. Puede tomar los siguientes valores. United-States, Cambodia, England, Puerto-Rico,       Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.	


Income (Ingresos): Variable objetivo de tipo binaria que representa los ingresos de la persona. Puede ser <=50K, si gana menos de 50000 dólares al año, o >50K si gana más de 50000 dólares al año.

De las variables cuantitativas anteriores, las variables Age, Education-num y Hours per week son discretas, ya que pueden tomar valores finitos, sin embargo, las variables fnlgwt, capital gain y capital loss son variables continuas, ya que pueden tomar infinitos valores.

Con el siguiente comando podemos ver un resumen de los datos, nos muestra el tipo de datos y los posibles valores que toma (los que hemos explicado antes).

```{r}
str(datos)
```

Hacemos un resumen estadístico de los datos con la función summary, ésta función nos va a dar en las variables cuantitativas, los principales valores estadísticos como son el mínimo, 1º, 2º y 3º cuartil, media y máximo. En las variables cuantitativas nos va a dar la cantidad de observaciones.

```{r}
# Hacemos el resumen estadístico de los datos cuantitativos
summary(datos)
```

Con el comando "describe()" obtenemos un resumen detallado de las variables del conjunto de datos. Para las variables numéricas nos proporciona los valores del summary, la desviación estándar, los valores menores y mayores. Para las categóricas, por cada variable, nos proporciona la frecuencia y la proporción de cada una de las categorias de la variable. En ambos casos nos proporciona el número de observaciones, los valores faltantes y la cantidad de valores distintos.

```{r}
library(Hmisc)
describe(datos)
```

Vamos a ver cuantas observaciones hay para cada opción de la variable respuesta.
```{r}
table(datos$Income.)

```
Vemos que aproximadamente el 75% de la  muestra, cobra menos de 50000 dólares al año. Esto se debe a que la mayoría de las personas cobran menos de esta cantidad, luego la muestra refleja la realidad de la sociedad. No podríamos coger una muestra igualitaria porque si no las predicciones no serían reales.


Vamos a realizar diferentes tablas dividiendo los datos en train y test y además, por cada uno de estos haremos 2 tablas, una con las variables cualitativas y otro con las cuantitativas.

```{r}
# Tabla que contiene los datos de las variables cuantitativas 
Cuantitativo_Datos= data.frame(Age=datos$Age,FNLWGT=datos$fnlwgt,CapitalGain=datos$Capital.gain,CapitalLoss=datos$Capital.loss,Hours=datos$Hours.per.week)

# Tabla que contiene los datos de las variables cualitativos 
Cualitativo_Datos = data.frame(WorkClass=datos$Workclass,Education=datos$Education,EstadoCivil=datos$Marital.status,Occupation=datos$Occupation.,RelationShip=datos$Relationship,Race=datos$Race,Sex=datos$Sex,NativeCountry=datos$Native.country,Income=datos$Income.)
```

```{r}
# Tabla que contiene los datos de la parte train de las variables cuantitativas 
Cuantitativo_DatosTrain= data.frame(Age=Datos_Train$Age,FNLWGT=Datos_Train$fnlwgt,CapitalGain=Datos_Train$Capital.gain,CapitalLoss=Datos_Train$Capital.loss,Hours=Datos_Train$Hours.per.week)

# Tabla que contiene los datos de la parte train de las variables cualitativas
Cualitativo_DatosTrain=data.frame(WorkClass=Datos_Train$Workclass,Education=Datos_Train$Education,EstadoCivil=Datos_Train$Marital.status,Occupation=Datos_Train$Occupation.,RelationShip=Datos_Train$Relationship,Race=Datos_Train$Race,Sex=Datos_Train$Sex,NativeCountry=Datos_Train$Native.country,Income=Datos_Train$Income.)
```

```{r}
# Tabla que contiene los datos de la parte test de las variables cuantitativas
Cuantitativo_DatosTest= data.frame(Age=Datos_Test$Age,FNLWGT=Datos_Test$fnlwgt,CapitalGain=Datos_Test$Capital.gain,CapitalLoss=Datos_Test$Capital.loss,Hours=Datos_Test$Hours.per.week)

# Tabla que contiene los datos de la parte test de las variables cualitativas
Cualitativo_DatosTest=data.frame(WorkClass=Datos_Test$Workclass,Education=Datos_Test$Education,EstadoCivil=Datos_Test$Marital.status,Occupation=Datos_Test$Occupation.,RelationShip=Datos_Test$Relationship,Race=Datos_Test$Race,Sex=Datos_Test$Sex,NativeCountry=Datos_Test$Native.country,Income=Datos_Test$Income.)
```

Vamos a realizar un gráfico en el que se van a comparar las variables númericas dos a dos, para ver que variables están mayormente relacionadas. Para realizar el gráfico usamos la función "pairs()".

```{r}
# Pairs para ver la relacion entre variables dos a dos
attach(Datos_Train)
pairs(Cuantitativo_DatosTrain)
```

En estas gráficas no se puede apreciar que haya ningún tipo de relación entre las variables númericas, ya que las nubes de puntos se distribuyen de forma aleatoria y sin mostrar ningun patrón. Para comprobar esto, vamos a realizar una matriz de correlación entre estas variables.

```{r}
cor(Cuantitativo_DatosTrain)
```

Con la matriz, nos damos cuenta de que las variables númericas no están correlacionadas, la mayor correlación que hay es de 0.10886121, que es un valor muy bajo, luego no existe ningún tipo de correlación.

# Análisis bivariado
Vamos a ver que distribución siguen algunas de las variables, para ello vamos a realizar un gráfico pairs() donde también se muestran los histogramas de cada variable.

```{r echo=TRUE}
panel.hist <- function(x, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5) )
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}

panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor * r)
}

pairs(Cuantitativo_Datos,upper.panel=panel.cor,diag.panel=panel.hist)
names(Cuantitativo_Datos)
```
Con este gráfico podemos ver los histogramas de cada variables, con lo que podríamos ver que distribución sigue cada variable cuantitativa.

Vamos a ver la distribucion de las cualitativas haciendo sus histogramas.

```{r}
ggplot(data = datos) +
geom_bar(mapping = aes(x = datos$Workclass))

ggplot(data = datos) +
geom_bar(mapping = aes(x = datos$Education))+ coord_flip()

ggplot(data = datos) +
geom_bar(mapping = aes(x = datos$Marital.status))+ coord_flip()

ggplot(data = datos) +
geom_bar(mapping = aes(x = datos$Occupation.))+ coord_flip()

ggplot(data = datos) +
geom_bar(mapping = aes(x = datos$Relationship))

ggplot(data = datos) +
geom_bar(mapping = aes(x = datos$Race))

ggplot(data = datos) +
geom_bar(mapping = aes(x = datos$Sex))

ggplot(data = datos) +
geom_bar(mapping = aes(x = datos$Native.country))+ coord_flip()
```
De la gráfica del país de nacimiento, vemos que la gran parte de la muestra nacieron en EEUU, luego para las predicciones, si usamos datos de otros países, donde la mayor parte de los datos en media pueden cambiar, no van a ser tan fiables. 

Vamos a realizar gráficos para comparar distintas variables con la variable respuesta.
Gráficos para comparar el income con las diferentes categorías de las variables
```{r}
# Comparacion del income con las edades 
ggplot(Datos_Train, aes(x = Age, fill = Income.)) + geom_bar()
```

En esta gráfica, podemos que hay más personas que cobran menos de 50000 dólares anuales y además, podemos ver que la mayor parte de las personas que cobran más de está cantidad tienen entorno a 40 años. Además, entorno a esta edad, la mitad de las personas cobran menos de está cantidad y la otra mitad más.

```{r}
# Comparacion del income con la Ocupacion 
ggplot(Datos_Train, aes(x = Occupation., fill=Income.)) + geom_bar() + coord_flip()
```
En este gráfico, podemos ver que en la mayoría de los trabajos, las personas cobran menos de 50000 dólares anuales, pero tambien podemos observar ciertas características importantes. Podemos ver que en el trabajo de Exec-managerial (ejecutivo) la mitad de las personas cobran más de 50000, que es un alto porcentaje comparado con los demás datos. En las variables de Prof-specialty, Craft_repair, sales y Transport-moving, el porcentaje es alto, siendo en la primera de estas entorno a un 33% y en las restantes entorno a un 25%. Además, en las variables Handlers-cleaners, Armed-Forces y Priv-house-serve todas las observaciones cobran menos de 50000.

```{r}
# Comparacion del income con las educacion 
ggplot(Datos_Train, aes(x = Education, fill = Income.)) + geom_bar() + coord_flip()
```
En este gráfico, podemos ver que con los estudios de Prof-school y Doctorate, el porcentaje para de cobrar más de 50000 dólares es muy alto, luego con estos estudios tienes una alta probabilidad de cobrar más de dicha cantidad. Sin embargo, vemos que en los estudios de la de 1º a 12º curso, el porcentaje es muy najo, luego hay pocas probabilidades de cobrar más de dicha cantidad.

```{r}
# Comparacion del income con el sexo 
ggplot(Datos_Train, aes(x = Sex, fill = Income.)) + geom_bar()
```
Con este gráfico, podemos ver que tanto en hombres como en mujeres, la mayor cantidad de personas gana menos de 50000 dólares anuales.

Además podemos hacer una comparación entre ambos sexos para ver si en proporción hay más mujeres u hombres que cobren más de 50000 dólares anuales.

```{r}
# Filtramos el número de mujeres que ganan menos de 50000
mujeres_menorDeCincuentaK <- subset(Datos_Train, Sex == " Female" & Income. == " <=50K")

# Contamos el número de mujeres con ingresos menores a $50,000
NumMujeres_menorDeCincuentaK <- nrow(mujeres_menorDeCincuentaK)
NumMujeres_menorDeCincuentaK

# Miramos el número total de mujeres que hay en la tabla Datos_Train
table(Datos_Train$Sex)

# El porcentaje es
214/248 * 100
```

Hacemos lo mismo para los hombres

```{r}
# Filtramos el número de hombres que ganan menos de 50000
hombres_menorDeCincuentaK <- subset(Datos_Train, Sex == " Male" & Income. == " <=50K")

# Contamos el número de hombres con ingresos menores a $50,000
NumHombres_menorDeCincuentaK <- nrow(hombres_menorDeCincuentaK)
NumHombres_menorDeCincuentaK

# Miramos el número total de hombres que hay en la tabla Datos_Train
table(Datos_Train$Sex)

# El porcentaje es
370/527 * 100
```
Para las mujeres obtenemos que el 86% cobra menos de 50000 y para hombres este porcentaje es del 70%. Como la diferencia es del 15%, que es una diferencia pequeña, no podemos afirmar que sea más probable que los hombres suelan cobrar más de 50000 y que para las mujeres esto suceda en menor medida. De igual manera, este caso lo volveremos a tratar más adelante para confirmar nuestras sospechas.


Por último, vamos a realizar gráficos de boxplot, en estos gráficos podemos observar valores atípicos en los datos así como medidas resumidas.

La línea en el centro de la caja representa la mediana, la caja representa el rango intercuartil, que es la diferencia entre el tercer cuartil y el primer cuartil, y proporciona una medida de la dispersión de los datos en la mitad central. Los bigotes salen de la caja y llegan hasta los valores mínimos y máximos y los puntos que se salen de los bigotes representan valores atípicos. Además, la forma de la caja da información sobre la distribución de los datos y la longitud de los bigotes, nos dan información de la variabilidad de los datos. 
```{r}
boxplot(Cuantitativo_Datos$Age, main = "Boxplot de Grupos", xlab = "Grupos", ylab = "Valores")
boxplot(Cuantitativo_Datos$FNLWGT, main = "Boxplot de Grupos", xlab = "Grupos", ylab = "Valores")
boxplot(Cuantitativo_Datos$CapitalGain, main = "Boxplot de Grupos", xlab = "Grupos", ylab = "Valores")
boxplot(Cuantitativo_Datos$CapitalLoss, main = "Boxplot de Grupos", xlab = "Grupos", ylab = "Valores")
boxplot(Cuantitativo_Datos$Hours, main = "Boxplot de Grupos", xlab = "Grupos", ylab = "Valores")
```


#Análisis de Componentes Principales

```{r}
#Target con colores
pca<-prcomp(Cuantitativo_DatosTrain,scale=T)

pca_dataframe <- as.data.frame(pca$x)
pca_dataframe_Income <- Datos_Train$Income.


par(mfrow=c(2,3))
ggplot(pca_dataframe, aes(x = PC1, y = PC2, color = Income.)) +
  geom_point() +
  labs(title = "PCA con Colores según el Income")

ggplot(pca_dataframe, aes(x = PC1, y = PC3, color = Income.)) +
  geom_point() +
  labs(title = "PCA con Colores según el Income")

ggplot(pca_dataframe, aes(x = PC1, y = PC4, color = Income.)) +
  geom_point() +
  labs(title = "PCA con Colores según el Income")

ggplot(pca_dataframe, aes(x = PC2, y = PC3, color = Income.)) +
  geom_point() +
  labs(title = "PCA con Colores según el Income")

ggplot(pca_dataframe, aes(x = PC2, y = PC4, color = Income.)) +
  geom_point() +
  labs(title = "PCA con Colores según el Income")

ggplot(pca_dataframe, aes(x = PC3, y = PC4, color = Income.)) +
  geom_point() +
  labs(title = "PCA con Colores según el Income")
```



```{r}
pca<-prcomp(Cuantitativo_DatosTrain,scale=T)
pca
```

PC1 asigna pesos. La mayoría de las ocasiones asigna el mismo signo a todas las covariables. En nuestro caso particular la variable FNLWGT posee signo positivo mientras que las otras poseen el signo contrario. Esto se puede interpretar de la siguiente manera:
  -	La variable FNLWGT, esta fuertemente correlacionada de forma positiva con PC1.
  -	Las variables que tienen el signo contrario sugieren una relación inversa con PC1.

Hay algunas posibles interpretaciones sobre esto, pero la que más nos convence (un vez realizado el análisis exploratorio de datos) es que  FNLWGT  tiene un impacto muy grande en la variabilidad general de los datos mientras que las demás variables, de forma INDIVIDUAL, tiene una relación no tan significativa.

Vamos a analizar y a interpretar la PC2. Esto es, las personas estarían ordenadas en cuanto a su Capital Loss en un sentido ponderando en sentido contrario el Capital Gain.

En PC3 el orden viene determinado solamente por FNLWGT.

El caso de PC4 es muy interesante pues se puede llegar a interpretar de la siguiente manera. Hay correlación negativa entre la variable Age y las horas trabajadas por semana. Luego esto quiere decir que aquellas personas que trabajan mas horas a la semana en promedio suelen ser personas jóvenes.

Si analizamos ahora PC5, observamos que  las personas estarían ordenadas en cuando a su Capital Gain en un sentido, ponderando en sentido contrario la variable edad.

## Variabilidad explicada

```{r}
plot(prcomp(Cuantitativo_DatosTrain,scale=T))
summary(prcomp(Cuantitativo_DatosTrain,scale=T))
```

Esta parte es la más importante para saber cuántas componentes elegimos. En la fila `Proportion of Variance` podemos comprobar que la proporción de varianza que explica cada una de las componentes es prácticamente la misma (en torno al 20%). Esto ya es un indicador de que este análisis no nos aclara ni nos ayuda de manera explicita a entender mejor los datos. Finalmente, se reafirma lo que estábamos intuyendo ya que en `Cumulative proportion` podemos hacernos una idea del numero de componentes principales que vamos a necesitar.

Nosotros consideramos que a partir de un 75% de variabilidad, ya es buen indicador. No obstante, este método se basa en la reducción de dimensionalidad, pero si en este caso, con el sesgo que hemos elegido, tenemos que emplear 4 componentes principales no nos resulta de gran utilidad este método.

## Análisis de los graficos

### PC1-PC2
```{r}
plot(prcomp(Cuantitativo_DatosTrain,scale=T)$x[,1:2])
```

Puntos cercanos en el mapa indican comportamiento similar en cuanto a las personas que estamos considerando en la base de datos. Del gráfico podemos inferir que hay ciertos puntos extremos en cuanto a las variables `Age`, `FNLWGT`, `Capital Gain`, `Capital Loss` y `Hours`. Pero, ¿en qué sentido? 

Esas personas situadas arriba a la izquierda de PC1 son personas con edad avanzada con un `Capital Gain` alto, `Capital Loss` alto, con muchas horas trabajadas a la semana y con un peso socio-económico (`FNLWGT`) muy bajo.

En cuanto a PC2, tenemos comportamientos extremos unos 5-10 puntos (situados abajo a la derecha) y en 5 puntos situados arriba a la izquierda.

  -	Vamos a analizar primero los 5-15 puntos. Son personas con un Capital Loss muy alto     y un Capital Gain muy bajo (esto lo sabemos gracias a los signos que nos proporciona     la tabla al realizar el summary).

  -	Los otros puntos restantes son personas con un Capital Gain muy alto y con un         Capital Loss muy bajo.

### PC1-PC3
```{r}
plot(prcomp(Cuantitativo_DatosTrain,scale=T)$x[,c(1,3)])
```

Puntos cercanos en el mapa indican comportamiento similar en cuanto a las personas que estamos considerando en la base de datos. Del gráfico podemos inferir que hay ciertos puntos extremos en cuanto a las variables `Age`, `FNLWGT`, `Capital Gain`, `Capital Loss` y `Hours`.  Pero, ¿en qué sentido? 

Esas personas situadas a la izquierda de PC1 son personas con edad avanzada con un `Capital Gain` alto, `Capital Loss` alto, con muchas horas trabajadas a la semana y con un peso socio-económico (`FNLWGT`) muy bajo.

En cuanto a PC3, tenemos comportamientos extremos en apenas 2 solos puntos, situados en la esquina superior derecha. La interpretación que podemos extraer es que son dos personas cuyo peso socioeconómico (`FNLWGT`) es mucho mas alto que el promedio de las demás personas.

### PC1-PC4
```{r}
plot(prcomp(Cuantitativo_DatosTrain,scale=T)$x[,c(1,4)])
```

Puntos cercanos en el mapa indican comportamiento similar en cuanto a las personas que estamos considerando en la base de datos. Del gráfico podemos inferir que hay ciertos puntos extremos en cuanto a las variables Age`, `FNLWGT`, `Capital Gain`, `Capital Loss` y `Hours`. Pero, ¿en qué sentido?

Esas personas situadas a la izquierda de PC1 son personas con edad avanzada con un `Capital Gain` alto, `Capital Loss` alto, con muchas horas trabajadas a la semana y con un peso socio-económico (`FNLWGT`) muy bajo.

Analicemos en este punto PC4. En este sentido tenemos comportamientos extremos en 1 solo punto. Esa persona posee una edad muy avanzada y trabaja pocas horas a la semana.

### Graficos restantes
```{r}
par(mfrow=c(2,3))
### PC2-PC3
plot(prcomp(Cuantitativo_DatosTrain,scale=T)$x[,c(2,3)])
### PC2-PC4
plot(prcomp(Cuantitativo_DatosTrain,scale=T)$x[,c(2,4)])
### PC3-PC4
plot(prcomp(Cuantitativo_DatosTrain,scale=T)$x[,c(3,4)])
```

En cuanto a las otras 3 graficas restantes, el procedimiento es el mismo. Es decir, buscar posibles puntos (personas) extremos y analizar que propiedades tienen.

Una pequeña barrera que tiene el PCA, es que solo tiene en cuenta las variables CUANTITATIVAS de la base de datos. Esto significa que no podemos asegurar ni extrapolar nada sobre las otras variables CUALITATIVAS que tenemos en nuestra base de datos en nuestro análisis de componentes principales.


Para finalizar esta parte del trabajo vamos a realizar un gráfico `biplot` para ayudar a visualizar las relaciones entre variables y observaciones.

## Grafico "biplot".
```{r}
biplot(pca)
```

Los estados casi se ordenan en la componente PC2 por Capital Gain en un sentido, y por Capital Loss en el otro, como ya hemos comprobado anteriormente.

# Analisis Cluster
El clustering es un proceso para agrupar un conjunto de datos en grupos (también conocidos como “clusters”) de manera que los datos dentro de cada grupo son similares entre sí, y diferentes del resto de grupos.
Existen varios algoritmos de clustering como K-Means y Hierarchical Clustering, cada uno con sus propias características y utilidades. 
Antes de trabajar con ellos vamos a escalar las tablas de datos. Escalamos los datos para que no haya grandes diferencias entre los valores de las columnas.

```{r}
n = dim(datos)[1]
p = dim(datos)[2]
DatosTrainEscalados <- scale(Cuantitativo_DatosTrain)
```

Cluster con k-means

Este algoritmo funciona de la siguiente manera. Primero, debemos decidir cuántos grupos queremos tener. Este número se llama k. Entonces, el algoritmo escoge al azar k observaciones, para ser los centros de cada grupo. A continuación, asigna cada observación restante al grupo cuyo centro es más cercano a ella. Finalmente, calcula una nueva posición para los centros de los grupos, tomando en cuenta las observaciones asignadas a ese grupo. Y repite este proceso varias veces hasta que las observaciones dejen de cambiar de grupo.
Vamos a probar con distinto número de clústers para ver como quedarían agrupadas las observaciones antes de calcular el numero optimo de clusters. Probamos con 2, 3, 4 y 7 centros.

```{r}
clusters2.datos=kmeans(DatosTrainEscalados,centers=2,nstart=25)
clusters2.datos$cluster
clusters2.datos$withinss

clusters3.datos=kmeans(DatosTrainEscalados,centers=3,nstart=25)
clusters3.datos$cluster
clusters3.datos$withinss

clusters4.datos=kmeans(DatosTrainEscalados,centers=4,nstart=25)
clusters4.datos$cluster
clusters4.datos$withinss

clusters7.datos=kmeans(DatosTrainEscalados,centers=7,nstart=25)
clusters7.datos$cluster
clusters7.datos$withinss
```


A continuación creamos un vector en el que almacenaremos la variabilidad para los diferentes números de centros. Debemos quedarnos con el número de clusters a partir del cual el descenso en la variabilidad es más suave. 

```{r}
#Inicializamos el vector
SSW <- vector(mode = "numeric", length = 15)

#Variabilidad de todos los datos, es decir, todos los datos como un único cluster
SSW[1] <- (n - 1) * sum(apply(DatosTrainEscalados,2,var)) 

#Variabilidad de cada modelo, desde 2 clusters hasta 15 clusters
for (i in 2:15) SSW[i] <- sum(kmeans(DatosTrainEscalados,centers=i,nstart=25)$withinss)

#Dibujamos un gráfico con el resultado
plot(1:15, SSW, type="b", xlab="Number of Clusters", ylab="Sum of squares within groups",pch=19, col="steelblue4")

centroides=aggregate(DatosTrainEscalados,by=list(clusters4.datos $cluster),FUN=mean)
t(centroides)  
```

En nuestro caso al ver la gráfica dudamos entre elegir 4 o 7 clusters asi que vamos a ver que obtenemos en cada caso.
Construimos ahora sí nuestro análisis cluster igual que antes y vemos cuales son los centros en cada uno de los casos y los representamos dibujando las variables dos a dos, donde cada color representa un cluster. 

```{r}
# Dibujamos los clusters en el scatterplot (variables 2a2)
nk=4 # nk es el numero de clusters 
pairs(DatosTrainEscalados,col= clusters4.datos$cluster,pch=19)
points(clusters4.datos$centers, col = 1:nk, pch = 19, cex=2)

#Para 7
centroides=aggregate(DatosTrainEscalados,by=list(clusters7.datos $cluster),FUN=mean)
t(centroides)  
# Dibujamos los clusters en el scatterplot (variables 2a2)
nk=7 # nk es el numero de clusters 
pairs(DatosTrainEscalados,col= clusters7.datos$cluster,pch=19)
points(clusters7.datos$centers, col = 1:nk, pch = 19, cex=2)
```

Vamos a ver definitivamente cual es el numero optimo de clusters poniendo como mínimo 2 y como máximo 15. 

```{r}
# ISAAC
library(NbClust)
nb <- NbClust(DatosTrainEscalados, distance = "euclidean", min.nc = 2, max.nc = 15, method = "kmeans")
```

Podemos observar que el numero optimo de clusters es 7.

Con los siguientes graficos veremos como se agrupan las observaciones en estos dos casos. 
```{r}
library(parameters)
# Ponemos los dos para comparar, el 7  lo dice el metodo el 4 pues para ver que pasa con menos
res_kmeans <- cluster_analysis(DatosTrainEscalados, n=4, method="kmeans")
plot(summary(res_kmeans))
 
res_kmeans <- cluster_analysis(DatosTrainEscalados, n=7, method="kmeans")
plot(summary(res_kmeans))


```
Con 4 clusters nuestro grafico nos proporciona la siguiente información. En el primer cluster se encuentran las observaciones que tienen valores altos de horas de trabajo y valores bajos del resto de variables. En el segundo cluster están las observaciones con mayor edad. En el tercero las que tienen alto fnlwgt pero baja edad. Por ultimo en el cuarto las que tienen un CapitalGain alto y un CapitalLoss muy alto.

Veamos que resultado obtenemos con 7 clusters. El primer cluster contiene observaciones con baja edad y horas. El segundo contiene observaciones con altas horas. El tercero contiene observaciones con alta edad y horas y extremadamente alto CapitalGain. El cuarto cluster contiene observaciones con alto CapitalLoss. El quinto contiene observaciones con alto fnlwgt. El sexto contiene observaciones con alta edad. Por ultimo el séptimo contiene observaciones con baja edad.



```{r}
# El grafico que sirve no nos vale ya que tenemos muchos datos y no se ve claramente
# # Guardamos el vector con el cluster correspondiente a cada país
# datos.clusters7 <- clusters7.datos$cluster
# # Vamos a hacer PCA para poder graficar los clusters en 2dimensiones!
# library(cluster)
# clusplot(DatosTrainEscalados, datos.clusters7, color=TRUE, shade=TRUE, labels=2,lines=0)

```

# Métodos jerarquicos
El cluster jerárquico es una técnica para agrupar datos que son similares entre sí. Es similar a la técnica de k-means, pero en lugar de dividir todo en un número fijo de grupos (k), el algoritmo va creando una jerarquía de grupos, donde cada grupo contiene subgrupos, y cada subgrupo contiene a su vez subgrupos, y así sucesivamente formando un dendrograma.

Hay dos maneras de hacerlo:
-Método ascendente: Comienza con cada punto de datos siendo un grupo y los va agrupando formando jerarquía
-Método descendente: comienza con todos los puntos de datos en un solo grupo y va dividiendo en subgrupos.

El resultado final es un dendrograma, que es similar a un árbol en el que cada hoja es un punto de datos y cada nodo interno es un grupo de puntos de datos. El nivel más alto del árbol es el grupo principal que contiene a todos los puntos de datos, y los niveles inferiores son los subgrupos.

Es importante mencionar que en este algoritmo es necesario definir una medida de distancia para poder comparar los datos, que en nuestro caso es la distancia euclidiana.

Para realizar esta sección se utiliza la función hclust, en la cual se pueden utilizar distintos métodos como “single”, “ward.D”, “complete”… En nuestro caso el que nos proporciona mayor información y visibilidad es el realizado con “ward.D”.

```{r}
#Probamos varios metodos de agrupacion y nos damos cuenta que el mejor es
# Primero obtenemos la matriz de distancias
d <- dist(Cuantitativo_DatosTrain, method = "euclidean")
fit <- hclust(d, method="ward.D")
plot(fit, labels=rownames(Cuantitativo_DatosTrain),cex=0.7)#Este

groups <- cutree(fit, k=7) # Fijamos en 7 el número de clusters
rect.hclust(fit, k=7, border="red")

fit2 <- hclust(d, method="single")
plot(fit2, labels=rownames(Cuantitativo_DatosTrain),cex=0.7)#Este no

fit3 <- hclust(d, method="complete")
plot(fit3, labels=rownames(Cuantitativo_DatosTrain),cex=0.7)#Este no

fit4 <- hclust(d, method="average")
plot(fit4, labels=rownames(Cuantitativo_DatosTrain),cex=0.7)#Este no

fit5 <- hclust(d, method="mcquitty")
plot(fit5, labels=rownames(Cuantitativo_DatosTrain),cex=0.7)#Este no

fit6 <- hclust(d, method="median")
plot(fit6, labels=rownames(Cuantitativo_DatosTrain),cex=0.7)#Este no

fit7 <- hclust(d, method="centroid")
plot(fit7, labels=rownames(Cuantitativo_DatosTrain),cex=0.7)#Este no


```
Aqui podemos ver los siete clusters.

```{r}


##
## FALTA HACER UN CLUSTER DE LOS PCA (hecho es lo copiado justo debajo(NO LO QUITO PARA AVISAROS))
##


clusters7.datos_PCA <- clusters7.datos$cluster
library(cluster)
clusplot(DatosTrainEscalados, clusters7.datos_PCA, color=TRUE, shade = TRUE, labels = 7, lines = 0)


#library(factoextra)
#fviz_cluster(clusters7.datos, data = Cuantitativo_DatosTrain)

groups <- cutree(fit, k=7) # Fijamos en 7 el número de clusters
plot(pca,col=groups)


rect.hclust(fit, k=7, border="red")




centroides=aggregate(DatosTrainEscalados,by=list(clusters7.datos $cluster),FUN=mean)
t(centroides)  
# Dibujamos los clusters en el scatterplot (variables 2a2)
nk=7 # nk es el numero de clusters 
pairs(DatosTrainEscalados,col= clusters7.datos$cluster,pch=19)
points(clusters7.datos$centers, col = 1:nk, pch = 19, cex=2)

```

Knn significa "k-nearest neighbors" que en español, significa "k-vecinos más cercanos".
El Knn es un modelo que se usa para realizar la clasificación de los datos. Este modelo se basa en la idea de que las observaciones que son similares tienden a estar cerca entre ellas.

KNN lo que va a hacer es clasificar un nuevo dato basándose en las características de sus vecinos más cercanos.

Para realizar el Knn, primero debemos definir el valor de k que va a ser el número de vecinos más cercanos que se tendrán en cuenta al clasificar un nuevo datos.
```{r}
library(class)
#library(cli)
library(caret)
# Indicamos las categorias de la variable respuesta
c2 <- factor(Datos_Train$Income.,labels = c("<=50K", ">50K"))
# Definimos el numero de vecinos mas cercanos que vamos a tener en cuenta para hacer la clasificacion
k1 = length(datos$Age)^((4)/(14+4))
# Creamos el modelo para el knn
modelo1 <- knn(train = Cuantitativo_DatosTrain, test = Cuantitativo_DatosTest, cl = c2, k = k1)

# Vemos la prediccion que hace el modelo knn
predicionKNN=table(modelo1, Datos_Test$Income.)

#confusionMatrix(table(modelo1, Datos_Test$Income.), positive="TRUE")
print(confusionMatrix(data = as.factor(predicionKNN),reference=as.factor(Cualitativo_DatosTest$Income.)))

```
La interpretación de esta tabla es la siguiente:
-	Personas que de verdad cobran <=50K y el modelo me lo ha predicho bien (<=50K) = 277
-	Personas que de verdad cobran >50K y el modelo me lo ha predicho mal (<=50K) = 83
-	Personas que de verdad cobran <=50K y el modelo me lo ha predicho mal (>50K) = 16
-	Personas que de verdad cobran >50K y el modelo me lo ha predicho bien (>50K) = 11

Estos datos nos muestra que el knn tiene una exactitud del 74.42% (TP+TN)/N. Que es un valor bastante alto, luego el modelo es muy exacto en su predicción.
```{r}
(277+11)/387
```
De manera recíproca tiene un error del 25.58% (FP+FN)/N
```{r}
(16+83)/387
```
Además, tiene una precisión del 83.83% TP/(TP+FP), Que es bastante alta.
```{r}
83/(83+16)
```

# Árboles de decisión
Primero hagamos una pequeña introducción sobre los Árboles de Decisión. 

Los árboles de decisión son modelos utilizados en la toma de decisiones. Los vamos a usar para clasificar, predecir y tomar decisiones. En los Árboles de decisión cada nodo representa una condición, y las ramas representan posibles respuestas, lo que nos ayuda a tomar decisiones, donde estas, están basadas en múltiples condiciones.

Al tratarse de un método útil en la toma de decisiones, nos vamos a ayudar de esta técnica para predecir si una nueva persona registrada en nuestra base de datos (con todas sus variables) gana anualmente más de 50K o menos de 50K.


```{r}
#Convertimos las variables cualitativas en factores
Datos_con_Factores <- datos
Datos_con_Factores[,2] = as.factor(Datos_con_Factores[,2])
Datos_con_Factores[,4] = as.factor(Datos_con_Factores[,4])
Datos_con_Factores[,6] = as.factor(Datos_con_Factores[,6])
Datos_con_Factores[,7] = as.factor(Datos_con_Factores[,7])
Datos_con_Factores[,8] = as.factor(Datos_con_Factores[,8])
Datos_con_Factores[,9] = as.factor(Datos_con_Factores[,9])
Datos_con_Factores[,10] = as.factor(Datos_con_Factores[,10])
Datos_con_Factores[,14] = as.factor(Datos_con_Factores[,14])
Datos_con_Factores[,15] = as.factor(Datos_con_Factores[,15])
```

Lo primero que vamos a hacer es generar una copia (objeto) de nuestra bases de datos, para trabajar con él, donde las variables cualitativas pasan a ser de tipo factor.

```{r}
library(rpart) # Cargamos la librería rpart
set.seed(123)
Datos_con_Factores.rp <- rpart(Datos_con_Factores[,15] ~., data=Datos_con_Factores[,1:14], method="class", cp=0.0001, parms=list(split="information"))
# summary(Datos_con_Factores.rp) <---No ayuda mucho a interpretar lo que sucede.
```

```{r}
#Parámetro de complejidad
plotcp(Datos_con_Factores.rp)
printcp(Datos_con_Factores.rp)
```

El comando `plotcp(Datos_con_Factores.rp)` genera un gráfico que muestra el costo-complejidad del árbol y ayuda a seleccionar el mejor modelo con la cantidad óptima de nodos (conocido como "poda" del árbol). Es decir queremos un equilibrio entre el costo y la complejidad del árbol. 

En este gráfico:
•	Eje X: nos muestra los valores de complejidad del árbol.
•	Eje Y: Representa el error de clasificación, asociado con cada árbol a medida que varía su complejidad.

Por lo tanto podemos observar como el punto del gráfico donde el error cuadrático medio es mínimo es en 0.037. En otras palabras este punto puede ser seleccionado como el árbol definitivo tras realizar la poda.

Si nos damos cuenta esto tiene sentido, ya que hay un momento, que es justo a partir del punto 0.037, en el cuál por mucho que hagamos el árbol más profundo, el error que se comete no disminuye, es más, sube. De otra forma, la tasa de acierto no mejora a parir de ese punto por mucho que hagamos el árbol más profundo.

Por tanto en este punto se obtiene el árbol más óptimo en términos de complejidad y rendimiento.



Al igual que hemos una copia de los datos originales, ahora vamos a proceder a realizar lo mismo, pero con los datos de entrenamiento y con los datos del test. Sin olvidarnos también de convertir las variables cualitativas en variables de tipo factor.

```{r}
Datos_Train_con_Factores = Datos_Train
Datos_Train_con_Factores[,2] = as.factor(Datos_Train_con_Factores[,2])
Datos_Train_con_Factores[,4] = as.factor(Datos_Train_con_Factores[,4])
Datos_Train_con_Factores[,6] = as.factor(Datos_Train_con_Factores[,6])
Datos_Train_con_Factores[,7] = as.factor(Datos_Train_con_Factores[,7])
Datos_Train_con_Factores[,8] = as.factor(Datos_Train_con_Factores[,8])
Datos_Train_con_Factores[,9] = as.factor(Datos_Train_con_Factores[,9])
Datos_Train_con_Factores[,10] = as.factor(Datos_Train_con_Factores[,10])
Datos_Train_con_Factores[,14] = as.factor(Datos_Train_con_Factores[,14])
Datos_Train_con_Factores[,15] = as.factor(Datos_Train_con_Factores[,15])

Datos_Test_con_Factores = Datos_Test
Datos_Test_con_Factores[,2] = as.factor(Datos_Test_con_Factores[,2])
Datos_Test_con_Factores[,4] = as.factor(Datos_Test_con_Factores[,4])
Datos_Test_con_Factores[,6] = as.factor(Datos_Test_con_Factores[,6])
Datos_Test_con_Factores[,7] = as.factor(Datos_Test_con_Factores[,7])
Datos_Test_con_Factores[,8] = as.factor(Datos_Test_con_Factores[,8])
Datos_Test_con_Factores[,9] = as.factor(Datos_Test_con_Factores[,9])
Datos_Test_con_Factores[,10] = as.factor(Datos_Test_con_Factores[,10])
Datos_Test_con_Factores[,14] = as.factor(Datos_Test_con_Factores[,14])
Datos_Test_con_Factores[,15] = as.factor(Datos_Test_con_Factores[,15])
```


En esta parte se nos presenta un pequeño problema. Al realizar los dos bancos de datos “Train” y “Test”, hay una persona en concreto, la cuál posee un valor de la variable `Education` en los datos de entrenamiento, que no aparece en el banco de datos “Test”.

Lo que hemos realizado es añadir a nuestros datos de entrenamiento esa fila del banco de datos de testeo.

```{r}
#Añadimos al train la fila que tiene Preschool pq esta en los test y no en el train
Datos_Train_con_Factores <- rbind(Datos_Train_con_Factores, Datos_Test_con_Factores[c('209'),])
```

## Predicciones Con el Árbol de Decisión 
```{r}
n=dim(Datos_con_Factores)[1]
y.pred=predict(Datos_con_Factores.rp,Datos_con_Factores[,-c(15)])
y.pred
```
Predict (EN FORMA DE PROBABILIDADES) con todos los datos de la tabla, basados en el arbol de decision `Datos_con_Factores.rp`.

```{r}
factores=colnames(y.pred)
y.pred.fact=matrix(0,n,1)
for (i in 1:n)
y.pred.fact[i]= factores[which.max(y.pred[i,])]
y.real.fact=Datos_con_Factores[,15]
table(y.pred.fact,y.real.fact) #<-Tabla de predicciones frente a valor real de todos los datos.

# sum(y.real.fact=="buff")
# sum(y.real.fact=="sick")
```

Al realizar esta tabla podemos observar como se relacionan los valores predichos, de los valores reales de TODOS LOS DATOS.

La interpretación de esta tabla es la siguiente:
-	Personas que de verdad cobran <=50K y el modelo me lo ha predicho bien (<=50K) = 1089
-	Personas que de verdad cobran >50K y el modelo me lo ha predicho mal (<=50K) = 109
-	Personas que de verdad cobran <=50K y el modelo me lo ha predicho mal (>50K) = 64
-	Personas que de verdad cobran >50K y el modelo me lo ha predicho bien (>50K) = 288


```{r}
x.train=Datos_Train_con_Factores
x.test=Datos_Test_con_Factores

#Datos train
Datos_Train_con_Factores.rp <- rpart(x.train[,15] ~., data=x.train[,1:14], cp=0.037, parms=list(split="information"))
```

Generamos un nuevo Árbol de Decisión, basado en el valor `cp = 0.037` obtenido en la parte anterior, y considerando ahora los datos de entrenamiento `x.train`.

```{r}
k=dim(x.train)[1]
y.pred.train=predict(Datos_Train_con_Factores.rp, x.train[,-c(15)])
y.pred.train
```

Predict (EN FORMA DE PROBABILIDADES) con los datos de entrenamiento, basados en el Arbol de decision `Datos_Train_con_Factores.rp`.

```{r}
factores=colnames(y.pred.train)
y.pred.train.fact=matrix(0,k,1)
for (i in 1:k)
y.pred.train.fact[i]= factores[which.max(y.pred.train[i,])]
y.real.train.fact=x.train[,15]
table(y.pred.train.fact,y.real.train.fact)
```

Al realizar esta tabla podemos observar cómo se relacionan los valores predichos, de los valores reales de los datos de entrenamiento.

La interpretación de esta tabla es la siguiente:
-	Personas que de verdad cobran <=50K y el modelo me lo ha predicho bien (<=50K) = 538
-	Personas que de verdad cobran >50K y el modelo me lo ha predicho mal (<=50K) = 83
-	Personas que de verdad cobran <=50K y el modelo me lo ha predicho mal (>50K) = 47
-	Personas que de verdad cobran >50K y el modelo me lo ha predicho bien (>50K) = 108


```{r}
# Datos test
##Datos_Test_con_Factores = Datos_Test_con_Factores[Datos_Test_con_Factores$Education != 'Preschool',]
m=dim(x.test)[1] #tamanno de la muestra de test
y.pred.test=predict(Datos_Train_con_Factores.rp, x.test[,-c(15)])
y.pred.test
```

Predict (EN FORMA DE PROBABILIDADES) con los datos de entrenamiento "Test", basados en el Arbol de decision `Datos_Train_con_Factores.rp`.

```{r}
factores=colnames(y.pred.test)
y.pred.test.fact =factores[max.col(y.pred.test)]
y.real.test.fact=x.test[,15]
table(y.pred.test.fact,y.real.test.fact)


## Tabla de confusionMatrix donde tenemos todas las medidas de rendimiento
print(confusionMatrix(data = as.factor(y.pred.test.fact),reference=as.factor(Datos_Test$Income.)))
```
Al realizar esta tabla podemos observar cómo se relacionan los valores predichos, de los valores reales de los datos “Test".

La interpretación de esta tabla es la siguiente:
-	Personas que de verdad cobran <=50K y el modelo me lo ha predicho bien (<=50K) = 260
-	Personas que de verdad cobran >50K y el modelo me lo ha predicho mal (<=50K) = 42
-	Personas que de verdad cobran <=50K y el modelo me lo ha predicho mal (>50K) = 33
-	Personas que de verdad cobran >50K y el modelo me lo ha predicho bien (>50K) = 52


Estos datos nos muestra que el random forest tiene una exactitud del 80.62% (TP+TN)/N. Que es un valor bastante alto, luego el modelo es muy exacto en su predicción.
```{r}
(260+52)/387
```
De manera recíproca tiene un error del 19.38% (FP+FN)/N
```{r}
(33+42)/387
```
Además, tiene una precisión del 56% TP/(TP+FP). Que no es muy alta pero está bien, luego el modelo no es muy preciso con las predicciones.
```{r}
42/(42+33)
```

# RANDOM FOREST

Un Bosque de Árboles es un conjunto de Árboles de Decisión donde cada árbol se entrena de manera independiente con una muestra aleatoria de los datos de entrenamiento y realiza predicciones. La predicción final del bosque se obtiene al promediar las predicciones de todos los árboles individuales. En estos, los nodos terminales contienen pocas observaciones, además, si dos observaciones caen en el mismo nodo terminal, entonces estas tienen mayor similaridad.

Vamos a realizar un random forest con nuestra muestra train y luego vamos a predecir la muestra del test y comentar los resultados para ver la precisión, exactitud...

Al crear el random forest con los datos del train y luego predecir los del test nos da un error de que las variables no coinciden. Para solucionarlo, como realmente si que coinciden, lo que hemos hecho es añadir la primera observacion de los datos train a los datos test y luego borrarsela. De esta manera las tablas se relacionan y no se produce este error.
```{r}
library(randomForest)
set.seed(123)

# Añadimos la primera fila de la tabla train a la tabla del test
x.test <- rbind(x.train[1,],x.test)
# Se la eliminamos
x.test <- x.test[-1,]
# Creamos el random forest
Datos_con_Factores.rf <- randomForest(x.train[,1:14], as.factor(x.train[,15]), ntree=100, importance=FALSE, proximity=TRUE, mtry=4, replace=FALSE)

# Predecimos para cada una de las obsesrvaciones de los datos del train la variable respuesta.
y.pred.train.rf= predict(Datos_con_Factores.rf, x.train[,-c(15)])
table.libreria.train=table(y.pred.train.rf,  as.factor(x.train[,15]))
# Predecimos para cada una de las obsesrvaciones de los datos del test la variable respuesta.
y.pred.test.rf=predict(Datos_con_Factores.rf, x.test[,-c(15)])
table.libreria.test=table(y.pred.test.rf,  as.factor(x.test[,15]))
# Imprimimos los resultados
print(table.libreria.train)
print(table.libreria.test)

print(confusionMatrix(data = as.factor(y.pred.test.rf),as.factor(x.test$Income.)), positive = unique(Income.)[1]
)
#levels(as.factor(x.test$Income.))[2]

```
HAY QUE COMENTAR LO DE LA CONFUSIONMATRIX YA QUE ELIGE SIEMPRE COMO CLASE POSITIVA <=50K.

Como vemos en los resultados, los datos del train los predice todos bien, esto es normal ya que ha sido entrenado con estos datos y los árboles han sido creados a través de estos.

En los resultados de las predicciones del test podemos ver que para los 298 que tienen unos ingresos menores de 50000, predice bien 258, que son los verdaderos negativos (TN), y a 40 los predice mal, que son los falsos negativos (FN). Por otra parte, vemos que para los 89 que realmente ganan más de 50000, predice bien 54, que corresponden con los verdaderos positivos (TP) y mal a 35, que osn los falsos positivos (FP).

Estos datos nos muestra que el random forest tiene una exactitud del 80.62% (TP+TN)/N. Que es un valor bastante alto, luego el modelo es muy exacto en su predicción.
```{r}
(258+54)/387
```
De manera recíproca tiene un error del 19.38% (FP+FN)/N
```{r}
(40+35)/387
```
Además, tiene una precisión del 60.67% TP/(TP+FP). Que no es muy alta pero está bien, luego el modelo no es muy preciso con las predicciones.
```{r}
54/(54+35)
```
Ahora vamos a ver si existe sesgo de sexo en las predicciones para evitar discriminaciones injustas. Para ello vamos a realizar un random forest en el que no se incluya la variable sexo y vamos a realizar las predicciones para las observaciones de las mujeres de los datos del test. Para estas mismas, vamos a realizar las predicciones usando el modelo anterior (en el que se usa la variable sexo), y vamos a comparar ambas predicciones para identificar si existe sesgo. Haremos lo mismo para los hombres.

```{r}

library(dplyr)
# Creamos una tabla con las observaciones que sean mujeres de los datos test
Datos_Test_con_Factores_Mujeres = subset(Datos_Test_con_Factores,Datos_Test_con_Factores$Sex == " Female")

# Le añadimos la primera fila de los datos del train y se la quitamos para asociar las tablas y que no se produzca un error
Datos_Test_con_Factores_Mujeres <- rbind(x.train[1,],Datos_Test_con_Factores_Mujeres)
Datos_Test_con_Factores_Mujeres <- Datos_Test_con_Factores_Mujeres[-1,]

# Creamos una tabla con las observaciones que sean hombres de los datos test
Datos_Test_con_Factores_Hombre = subset(Datos_Test_con_Factores,Datos_Test_con_Factores$Sex == " Male")

# Le añadimos la primera fila de los datos del train y se la quitamos para asociar las tablas y que no se produzca un error
Datos_Test_con_Factores_Hombre <- rbind(x.train[1,],Datos_Test_con_Factores_Hombre)
Datos_Test_con_Factores_Hombre <- Datos_Test_con_Factores_Hombre[-1,]
```

```{r}
# Creamos un random forest con todas las observaciones del train pero sin usar la variable sexo
Datos_con_Factores_SinSexo.rf <- randomForest(x.train[,-c(10,15)], as.factor(x.train[,15]), ntree=100, importance=FALSE, proximity=TRUE, mtry=4, replace=FALSE)

# Hacemos la prediccion de las mujeres usando el random forest sin la variable sexo 
pred_Mujeres_SinSexo.rf=predict(Datos_con_Factores_SinSexo.rf, Datos_Test_con_Factores_Mujeres[,-c(15)])
table.pred_Mujeres_SinSexo.rf=table(pred_Mujeres_SinSexo.rf,  as.factor(Datos_Test_con_Factores_Mujeres[,15]))
print(table.pred_Mujeres_SinSexo.rf)

# Hacemos la prediccion de las mujeres usando el random forest con la variable sexo 
pred_Mujeres.rf=predict(Datos_con_Factores.rf, Datos_Test_con_Factores_Mujeres[,-c(15)])
table.pred_Mujeres.rf=table(pred_Mujeres.rf,  as.factor(Datos_Test_con_Factores_Mujeres[,15]))
print(table.pred_Mujeres.rf)
```
Podemos ver que en ambos casos la predicción es la misma, luego podemos decir que para las mujeres no hay sesgo de sexo.
```{r}

# Hacemos la prediccion de los hombres usando el random forest sin la variable sexo 
pred_Hombres_SinSexo.rf=predict(Datos_con_Factores_SinSexo.rf, Datos_Test_con_Factores_Hombre[,-c(15)])
table.pred_Hombres_SinSexo.rf=table(pred_Hombres_SinSexo.rf,  as.factor(Datos_Test_con_Factores_Hombre[,15]))
print(table.pred_Hombres_SinSexo.rf)

# Hacemos la prediccion de los hombres usando el random forest con la variable sexo 
pred_Hombres.rf=predict(Datos_con_Factores.rf, Datos_Test_con_Factores_Hombre[,-c(15)])
table.pred_Hombres.rf=table(pred_Hombres.rf,  as.factor(Datos_Test_con_Factores_Hombre[,15]))
print(table.pred_Hombres.rf)

```
Para el caso de los hombres, la diferencia es mínima, de  observaciones, en las que usando la variable sexo, las predice bien, son verdaderos negativos y sin usar la variable las predice mal, son falsos positivos. Como laa diferencia es pequeña podemos afirmar que tampoco existe sesgo de sexo.

Como en ambos casos hemos visto que no existe un sesgo para cada sexo, podemos decir que el modelo no tiene sesgo para el sexo.

#SVM
```{r}
gamma_est = 1/apply(Cuantitativo_DatosTrain, 2, sd)
norma2 = function(x) sqrt(sum(x^2))
cost_est = apply(Cuantitativo_DatosTrain, 2, norma2)


# Calculamos el modelo utilizando RBF
svm1 = svm(Cuantitativo_DatosTrain, as.factor(Cualitativo_DatosTrain$Income), type="C-classification", kernel="radial", gamma=mean(gamma_est), cost=mean(cost_est), scale=T,probability = T)

svm1 = svm(Cuantitativo_DatosTrain, as.factor(Cualitativo_DatosTrain$Income), type="C-classification", kernel="radial", gamma=mean(gamma_est), cost=mean(cost_est), scale=T)

# Predecimos

pred1 = predict(svm1, Cuantitativo_DatosTest)

pred2 = predict(svm1, Cuantitativo_DatosTrain)
# Calculamos la matriz de confusión

table(pred1, x.test[,15])
table(pred2, as.factor(Cualitativo_DatosTrain$Income))

```


# Conclusiones Finales


# Nuevas tendencias.

Tras la realización de este trabajo, nos planteamos lass siguientes cuestiones que podriamos resolverlas en un futuro.

En cuanto a la variable `fnlwgt` tenemos muchos indicios de que se trata de una variable, que a parte de tratarse del peso socio-economico de una persona, es una variable que elimina cualquier tipo de sesgo que pueda existir en nuestra base de datos.

Entonces nos planteamos la siguiente pregunta, ¿que ocurriria si eliminasemos esa variable de nustro conjunto de variables?

Un trabajo futuro sería, por ejemplo, analizar si tras eliminar la variable `fnlwgt` existiría algún tipo de sesgo.

Por otra parte, se nos plantea otro escenario. Dado un individuo que no gana mas de 50K que podría tener condiciones para ganarlo, que recomendación podemos dar a esa persona para que gane mas de 50k.
